# Parametric Tests

Parametric tests are used when the data is normally distributed and the sample
size is large enough to assume that the sample mean is normally distributed.
Parametric tests are more powerful than non-parametric tests, meaning that they
are more likely to detect a significant difference when one exists. However,
they are also more sensitive to violations of their assumptions, such as
non-normality or unequal variances. In particular, parametric tests are
sensitive to outliers, which can skew the results of the test. Before we
consider parametric tests, we need to check that our data meets the assumptions
of the test.

### Assumptions of Parametric Tests

Parametric tests make several assumptions about the data, including:

- **Normality**: The data is normally distributed. This assumption is
  particularly important for tests that compare means, such as the t-test and
  ANOVA. If the data is not normally distributed, we may need to use a
  non-parametric test instead.
- **Homogeneity of Variance**: The variances of the groups being compared are
  equal. This assumption is important for tests that compare means, such as the
  t-test and ANOVA. If the variances are not equal, we may need to use a
  modified version of the test that does not assume equal variances.
- **Independence**: The observations are independent of each other. This
  assumption is important for all hypothesis tests, as violating it can lead to
  biased results. For example, if the observations are time series data, we may
  need to use a different test that accounts for the autocorrelation between
  observations.

### Types of Parametric Tests

In this section, we will discuss two of the most commonly used parametric tests:
the t-test and ANOVA. These tests are used to compare the means of two or more
groups, respectively.

### T-Tests

T-tests are used to compare the means of two groups. We'd typically use T-tests
to compare the means of two groups to determine if there is a significant
difference between them. For instance if we want to compare whether a marketing
campaign has increased sales, we could use a T-test to compare the mean sales
before and after the campaign.

There are three primary types of t-tests:

- **One-sample t-test**: Compares the mean of a sample to a known population
  mean.
- **Independent samples t-test**: Compares the means of two _independent_
  groups.
- **Paired samples t-test**: Compares the means of two related groups (e.g.,
  before and after measurements).

In practice, the way to perform these tests is similar, but the underlying
assumptions and interpretations differ. In a One-Sample test, we are comparing
the mean of a sample to a known population mean. This could be used to determine
if a sample mean is significantly different from a known value. For instance
whether health outcomes in a specific area are significantly different from the
national average. In an Independent Samples test, we are comparing the means of
two independent groups. For instance, we could use this to determine if there is
a significant difference in test scores between two schools.  
In a Paired Samples test, we are comparing the means of two related groups. The
t-test statistic is calculated based on the difference between the sample means,
the standard error of the difference, and the degrees of freedom. We would use
this test if we wanted to determine if there was a significant difference in
test scores before and after a training program.

### Outputs of the T-Test

The t-test will provide a number of outputs, including the **t-statistic**, the
**degrees of freedom**, and the **p-value**.

#### The T-Test Statistic

The t-test statistic (or `t-statistic`) is calculated based on the difference
between the sample means, the standard error of the difference, and the degrees
of freedom. The value may be positive or negative, depending on the direction of
the difference. The larger the t-statistic, the more likely it is that the
difference between the means is statistically significant. A t-statistic of 0
indicates that there is no difference between the means of the two groups. A
good rule of thumb is that a t-statistic greater than 2 or less than -2 is
considered statistically significant.

#### Degrees of Freedom

The degrees of freedom is a measure of the number of independent pieces of
information available to estimate a parameter. In the context of a t-test, the
degrees of freedom is calculated based on the sample sizes of the two groups
being compared. The degrees of freedom is used to determine the critical value
of the t-statistic, which is used to determine if the difference between the
means is statistically significant.

#### P-Value

The p-value is a measure of the probability that the observed difference between
the means is due to chance. A p-value less than 0.05 is typically considered
statistically significant, meaning that there is less than a 5% chance that the
observed difference is due to chance. If the p-value is less than 0.05, we
reject the null hypothesis and conclude that there is a significant difference
between the means of the two groups.

## Activity 5.1.1: Perform a T-Test

In the [activities folder](../Activities/5/5.1/), there is a dataset,
`data.csv`. Run the [Python](../Activities/5/5.1/5.1.1.ipynb) and
[R](../Activities/5/5.1/5.1.1.Rmd) notebooks to see the difference in the output
of the t-test in the two languages.

Try to consider which output is easier to interpret, and why.

### Discussion

R has a more comprehensive output, and is arguably easier to develop and
interpret. Cevn though I prefer Python generally, my preference is to use R for
hypothesis testing, as it provides more information about the test and the data.

## Analysis of Variance (ANOVA)

ANOVA is a statistical technique used to determine whether there are significant
differences among the means of **three or more** groups. We would use ANOVA when
we have more than two groups to compare, for instance if we wanted to compare
the average sales across multiple regions.

It is a versatile tool used in various fields, including psychology, biology,
and economics. There are several types of ANOVA, but we will focus on one-way
ANOVA in this article.

### One-Way ANOVA

One-way ANOVA is used when you have one categorical independent variable
(factor) with three or more levels and a continuous dependent variable. The null
hypothesis for a one-way ANOVA is that there is no difference between the means
of the groups, while the alternative hypothesis is that at least one group mean
is different.

### Two-Way ANOVA

Two-way ANOVA is used when you have two categorical independent variables
(factors) and a continuous dependent variable. The null hypothesis for a two-way
ANOVA is that there is no interaction between the two factors, while the
alternative hypothesis is that there is an interaction between the two factors.

### Factorial ANOVA

Factorial ANOVA is used when you have two or more independent variables
(factors) and a continuous dependent variable. The null hypothesis for a
factorial ANOVA is that there is no interaction between the factors, while the
alternative hypothesis is that there is an interaction between the factors.

### Between-Subjects ANOVA

Between-subjects ANOVA is used when each participant is assigned to only one
group. The null hypothesis for a between-subjects ANOVA is that there is no
difference between the means of the groups, while the alternative hypothesis is
that at least one group mean is different.

### Within-Subjects ANOVA

Within-subjects ANOVA is used when each participant is assigned to more than one
group. The null hypothesis for a within-subjects ANOVA is that there is no
difference between the means of the groups, while the alternative hypothesis is
that at least one group mean is different.

### Mixed-Design ANOVA

Mixed-design ANOVA is used when you have both between-subjects and
within-subjects factors. The null hypothesis for a mixed-design ANOVA is that
there is no interaction between the between-subjects and within-subjects
factors, while the alternative hypothesis is that there is an interaction
between the factors.

### Assumptions of ANOVA

To use ANOVA, certain assumptions must be met:

- **Normality:** The data in each group should be normally distributed.
- **Homogeneity of variance:** The variance of the dependent variable should be
  equal across all groups.

### The ANOVA Table

#TODO
<https://opentextbc.ca/introductorybusinessstatistics/chapter/f-test-and-one-way-anova-2/#:~:text=The%20second%20is%20one%2Dway,from%20populations%20with%20the%20same>

The ANOVA table provides a summary of the ANOVA results, including the sum of
squares, degrees of freedom, mean squares, F-statistic, and p-value. The sum of
squares is the sum of the squared differences between the observed values and
the group means. The degrees of freedom are used to calculate the mean squares,
which are the sum of squares divided by the degrees of freedom. The F-statistic
is the ratio of the between-group variance to the within-group variance, and the
p-value is the probability of observing the F-statistic under the null
hypothesis. A small p-value indicates that there is a significant difference
between the group means.

Depending on the tool you use, the ANOVA table will look something like this:

| Source         | Sum of Squares | Degrees of Freedom | Mean Square | F-Statistic | P-Value |
| -------------- | -------------- | ------------------ | ----------- | ----------- | ------- |
| Between Groups |                |                    |             |             |         |
| Within Groups  |                |                    |             |             |         |
| Total          |                |                    |             |             |         |

### Interpreting The results

#### Sum of Squares

The sum of squares between groups is a measure of the variation between the
group means. A large sum of squares between groups indicates that there is a
**significant difference** between the group means.

#### Degrees of Freedom

The degrees of freedom between groups is the number of groups minus one. It is
used to calculate the mean squares between groups. A large degrees of freedom
between groups indicates that there is a **significant difference** between the
group means; one or more groups are different enough to be considered
significant, potentially undermining the null hypothesis.

#### Mean Squares

The mean squares between groups is the sum of squares between groups divided by
the degrees of freedom between groups. It is used to calculate the F-statistic.
A large mean squares between groups indicates that there is a **significant
difference** between the group means.

### F-Statistic

ANOVA uses the F-statistic to test the equality of means. The F-statistic is the
ratio of the between-group variance to the within-group variance. A large
F-statistic indicates that there is a significant difference between the group
means.

### P-Value

The p-value is the probability of observing the F-statistic under the null
hypothesis. A small p-value indicates that there is a significant difference
between the group means.

### Implementing ANOVA in Python and R

#### Python

Python offers several libraries for performing ANOVA, but we will focus on
`statsmodels`.

```python
import pandas as pd
from scipy import stats

# Sample data (replace with your data)
data = {'group': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],
        'value': [2, 4, 5, 3, 1, 6, 2, 5, 4]}
df = pd.DataFrame(data)

# Prepare the data for ANOVA
grouped_data = [df[df['group'] == group]['value'] for group in df['group'].unique()]

# Perform the ANOVA test
f_stat, p_val = stats.f_oneway(*grouped_data)
print(f"F-statistic: {f_stat}, P-value: {p_val}")
```

#### R

R provides the `aov` function for ANOVA.

Code snippet

```R
# Sample data (replace with your data)
data <-data.frame(group = factor(c("A", "B", "C", "A", "B", "C", "A", "B", "C")),
                  value = c(2, 4, 5, 3, 1, 6, 2, 5, 4))

# Fit the model
model <-aov(value ~ group, data = data)
summary(model)
```

### Post-Hoc Tests

If the ANOVA result is significant, post-hoc tests can be used to determine
which specific groups differ. Common post-hoc tests include Tukey's HSD,
Bonferroni, and Scheffé.
