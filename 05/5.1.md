# 5.1: Types of Hypothesis Tests 

Before we can begin to understand hypothesis tests, we need to understand the different types of hypothesis tests that are commonly used in data science. Hypothesis tests are used to determine if there is a significant difference between two groups or if a relationship exists between two variables. There are many different types of hypothesis tests, but they can be broadly categorized into two groups: parametric and non-parametric tests.

## Parametric Tests

Parametric tests are used when the data is normally distributed and the sample size is large enough to assume that the sample mean is normally distributed. Parametric tests are more powerful than non-parametric tests, meaning that they are more likely to detect a significant difference when one exists. However, they are also more sensitive to violations of their assumptions, such as non-normality or unequal variances.  In particular, parametric tests are sensitive to outliers, which can skew the results of the test.  Before we consider parametric tests, we need to check that our data meets the assumptions of the test.

### Assumptions of Parametric Tests

Parametric tests make several assumptions about the data, including:

+ **Normality**: The data is normally distributed. This assumption is particularly important for tests that compare means, such as the t-test and ANOVA. If the data is not normally distributed, we may need to use a non-parametric test instead.
+ **Homogeneity of Variance**: The variances of the groups being compared are equal. This assumption is important for tests that compare means, such as the t-test and ANOVA. If the variances are not equal, we may need to use a modified version of the test that does not assume equal variances.
+ **Independence**: The observations are independent of each other. This assumption is important for all hypothesis tests, as violating it can lead to biased results. For example, if the observations are time series data, we may need to use a different test that accounts for the autocorrelation between observations.

### T-Tests

T-tests are used to compare the means of two groups. We'd typically use T-tests to compare the means of two groups to determine if there is a significant difference between them. For instance if we want to compare whether a marketing campaign has increased sales, we could use a T-test to compare the mean sales before and after the campaign.  

There are three primary types of t-tests:   

+ **One-sample t-test**: Compares the mean of a sample to a known population mean. 
+ **Independent samples t-test**: Compares the means of two *independent* groups.   
+ **Paired samples t-test**: Compares the means of two related groups (e.g., before and after measurements).

In practice, the way to perform these tests is similar, but the underlying assumptions and interpretations differ.  In a One-Sample test, we are comparing the mean of a sample to a known population mean.  This could be used to determine if a sample mean is significantly different from a known value.  For instance whether health outcomes in a specific area are significantly different from the national average.  In an Independent Samples test, we are comparing the means of two independent groups.  For instance, we could use this to determine if there is a significant difference in test scores between two schools.  
In a Paired Samples test, we are comparing the means of two related groups.  The t-test statistic is calculated based on the difference between the sample means, the standard error of the difference, and the degrees of freedom. We would use this test if we wanted to determine if there was a significant difference in test scores before and after a training program.

### Outputs of the T-Test

The t-test will provide a number of outputs, including the **t-statistic**, the **degrees of freedom**, and the **p-value**.  

#### The T-Test Statistic
The t-test statistic (or `t-statistic`) is calculated based on the difference between the sample means, the standard error of the difference, and the degrees of freedom. The value may be positive or negative, depending on the direction of the difference. The larger the t-statistic, the more likely it is that the difference between the means is statistically significant.  A t-statistic of 0 indicates that there is no difference between the means of the two groups. A good rule of thumb is that a t-statistic greater than 2 or less than -2 is considered statistically significant.

#### Degrees of Freedom

The degrees of freedom is a measure of the number of independent pieces of information available to estimate a parameter. In the context of a t-test, the degrees of freedom is calculated based on the sample sizes of the two groups being compared. The degrees of freedom is used to determine the critical value of the t-statistic, which is used to determine if the difference between the means is statistically significant.

#### P-Value

The p-value is a measure of the probability that the observed difference between the means is due to chance. A p-value less than 0.05 is typically considered statistically significant, meaning that there is less than a 5% chance that the observed difference is due to chance. If the p-value is less than 0.05, we reject the null hypothesis and conclude that there is a significant difference between the means of the two groups.


## Activity 5.1.1: Perform a T-Test

In the [activities folder](../Activities/5/5.1/), there is a dataset, `data.csv`.  Run the [Python](../Activities/5/5.1/5.1.1.ipynb) and [R](../Activities/5/5.1/5.1.1.Rmd) notebooks to see the difference in the output of the t-test in the two languages.  

Try to cosider which output is easier to interpret, and why.

### Discussion

R has a more comprehensive output, and is arguably easier to develop and interpret.  Cevn though I prefer Python generally, my preference is to use R for hypothesis testing, as it provides more information about the test and the data.  
