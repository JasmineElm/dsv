# Ethics in Data Science

You'll cover fundamental ethics in other modules, but there are a couple of
ethical considerations that are particularly relevant to data science. These
are:

- asymmetries of information
- biases in data
- privacy and security

> What’s the most evil thing that can be done with this? \[...\]By asking the
> team to imagine what their impact could be if you abandon all constraints, you
> allow for a conversation that will help you identify opportunities that you
> would otherwise miss, and refine good ideas into great ones. We don’t want to
> build “evil” products, but subversive thinking is a good way to get outside
> the proverbial box.

@patilDataDriven2015

---

## Activity 6.1.0

_Allow 1 hour_

Read Appendix H of "A Hands-On Introduction to Data Science" by Gutman and
Goldmeyer. This appendix discusses Ethical Considerations in Data Science.
Consider how these issues may affect your work as a data scientist.

---

### Asymmetries of Information

An asymmetry of information gives the party with more information an advantage
in a transaction. Asymmetries of information are when one party in a transaction
has more information than the other. This gives the party with more information
an advantage in the transaction. For instance, if you are buying a used car, the
seller knows more about the car than you do. This means that the seller has an
advantage in the transaction. This is an example of an asymmetry of information.

In [Week One](Week_1-Introduction.md) we considered the Financial Crisis
of 2008. No single factor caused to the financial crisis, and no single person
knew the risks. Instead it was a combination of asymmetries of information that
led to the crisis. The crisis was caused by this combination of partial truths:

**Borrowers** knew that they were taking on risky loans, but they believed that
they would be able to refinance or sell their homes before the rates went up.
**Lenders** knew that the loans they were offering were risky, but they believed
that the risk was spread across the financial system, so they would not be
affected if the loans went bad. **Investment Banks** knew that the MBS they were
buying were potentially risky, but they believed that the underlying mortgages
were sound. **Regulators** knew that the financial system was taking on more
risk, but they believed that the market would self-correct.

The lenders had more information than the borrowers, the investment banks had
more information than the lenders, and the regulators had more information than
the investment banks. This meant that the risks were not fully understood, and
the consequences were not fully appreciated.

## Activity 6.1.1:

_Allow 1 hour_

look up the seminal paper on this subject by George Akerlof, "The Market for
Lemons: Quality Uncertainty and the Market Mechanism" (1970). This paper is a
classic in the field of economics and is a clear example of how asymmetries of
information can affect markets.

<https://doi.org/10.1016/B978-0-12-214850-7.50022-X>

### Privacy and Security

Data science relies on data, and data is often personal. This means that data
science can raise privacy and security concerns. It is important to be aware of
these concerns and to take steps to protect privacy and security.

There are laws and regulations that govern the use of data. For instance the
GDPR (General Data Protection Regulation) seeks to limit the use of personal
data and to protect the privacy of individuals. It has

Whilst these uses are important, it is also important to remember that data
science can be used for good or ill. It is important to be aware of the ethical
implications of data science and to use data science responsibly.
@zuboffAgeSurveillanceCapitalism2019 argues that data science is being used to
manipulate people and to control society. She argues that data science is being
used to create a new form of power that she calls "surveillance capitalism". It
is important to be aware of these issues and to use data science responsibly.

## Activity 6.1.2

_Allow 30 minutes_ Shoshana Zuboff argues that data science is being used to
manipulate people and to control society. Watch this video of her discussing the
themes that underpin her book "The Age of Surveillance Capitalism" and consider
the ethical implications of data science.
<https://www.youtube.com/watch?v=8HzW5rzPUy8>

Zuboff's ideas have been widely discussed and debated. For instance, Yiannis
Varoufakis has expanded on Zuboff's ideas in his book "Another Now". In this
book, Varoufakis argues that data science is being used to create a new form of
power that he calls "technofeudalism". It is important to be aware of these
issues and to use data science responsibly.

## Activity 6.1.3

_Allow 1 hour_ Listen to
[this podcast](https://www.philosophizethis.org/podcast/episode-201-transcript-bkx3e-37rkx-bpl83-ysc9b-kkg62)
where Varoufakis discusses the themes that underpin his book "Another Now" and
consider the ethical implications of data science.

These somewhat dystopian views of massive companies capturing, controlling and
manipulating data for their own ends are not the only narrative. As we saw in
week two, open data can be a force to empower citizens and hold governments to
account.

For instance, data science can be used to predict the spread of diseases, to
predict the weather, and to predict the outcome of elections. It is important to
be aware of the ethical implications of data science and to use data science
responsibly.

## Activity 6.1.3

_Allow 30 minutes_

The NHS collects general practice data for planning and research purposes. This
data is used to improve patient care and to plan services. The data is collected
in a way that intends to protects patient privacy and security.

Read the NHS guidance on the collection of general practice data and consider
the ethical implications of using data science in this way.

[https://digital.nhs.uk/data-and-information/data-collections-and-data-sets/data-collections/general-practice-data-for-planning-and-research#note-for-gp-practices-and-gp-system-suppliers-legal-documents](https://digital.nhs.uk/data-and-information/data-collections-and-data-sets/data-collections/general-practice-data-for-planning-and-research#note-for-gp-practices-and-gp-system-suppliers-legal-documents)

### Discussion

Although the NHS claims "rigorous processes in place to ensure that data we
manage is collected, processed and stored securely", campaigners have claimed
the type of data collected

## Activity 6.1.3

_Allow 1 hour_ Building on the themes Zuboff discusses, consider the ethical
implications of using data science to predict behaviour. Read the following
article and consider the ethical implications of using predictive analytics in
this way.

### Target's Predictive Analytics

In 2012, Forbes reported that Target (a major supermarket in the US) had sent a
teenager a coupon book for expectant mothers @hillHowTargetFigured2012. The
teenager's father was furious, but when he went to the store to complain, he
found out that his daughter was indeed pregnant. Target had used predictive
analytics to predict that the teenager was pregnant based on her shopping
habits. Whilst likely apocryphal @piatetskyDidTargetReally2014, this story
illustrates the power of predictive analytics and the ethical implications of
using data science.

## Activity 6.1.4

_Allow 30 minutes_

The New York Times has a more nuanced take on this story. Read the article and
consider the ethical implications of using predictive analytics in this way.

<https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html>

## Bias in Data

We'll discuss bias in data science in more detail in week 6. For now, it is
enough to be aware that the datasets that we are working with may have some
implicit biases. These biases can affect the results of our analysis and the
conclusions that we draw from them. It is important to be aware of these biases
and to take steps to mitigate them. Examples of biases in data include poor
coverage, selection bias, and measurement bias.

## Activity 6.1.5

_Allow 1 hour_

Read Chapter 13 of Becoming a Data Head: How to Think, Speak, and Understand
Data Science by Gutman and Goldmeyer. This chapter discusses the problems of
bias in data science. Consider the ethical implications of bias in data science.

## Privacy and Security

There is a tension between privacy and security. On the one hand, we want to
offer the best possible _personalised_ service to our users. On the other hand,
we want to protect their privacy. This is a difficult balance to strike. It is
important to be aware of the ethical implications of data science and to use
data science responsibly. There is no simple answer to this question.

### Facebook and Cambridge Analytica

A "classic" example is ther Cambridge Analytica scandal. In 2018, it was
revealed that Cambridge Analytica had harvested the personal data of millions of
Facebook users without their consent. This data was then used to target
political advertising. This scandal raised serious concerns about privacy and
security. Cambridge Analytica "scraped" personal information including
motivations from Facebook , using innocuous looking quizzes. This data was then
used to target hyper-precise political advertising. The case is discussed
extensively in Chris Wylie's book "Mindf\*ck".

### Facebook and Advertising Opt-Outs

Perhaps in reaction to the Cambridge Analytica scandal, Facebook has introduced
a paid-for service that allows users to opt-out of targeted advertising. This
service is called "Subscription - No Ads". This service is discussed in the
following article:
<https://about.fb.com/news/2023/10/facebook-and-instagram-to-offer-subscription-for-no-ads-in-europe/>

## Activity 6.1.6

_Allow 30 minutes_

Meta's "Subscription - No Ads" service promises to protect user privacy by not
using personal data for advertising. This does not mean that personal
information is not collected, however. Read the article and consider the ethical
implications of this service.
<https://arstechnica.com/tech-policy/2024/07/meta-risks-sanctions-over-sneaky-ad-free-plans-confusing-users-eu-says/>
