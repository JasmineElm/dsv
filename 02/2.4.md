# 2.4: Conclusion

This week, we covered the basics of finding and evaluating datasets. We looked
at the Open Data movement and how it has made vast amounts of data available to
the public. We explored the different types of datasets available online, from
cities and regions to countries, healthcare, finance, climate, and research. We
also discussed the rise of citizen data science and how individuals from a wide
range of backgrounds are using data science techniques to analyse data and tell
stories.

One of the building blocks of data science is the dataset, and how it is
constructed. Being able to identify the data-types and the structure of the data
is essential to understanding the data. We may be lucky enough to have a data
dictionary or metadata that describes the data, but often we will need to infer
the structure of the data from the data itself. We discussed how to identify the
data types of the columns in our dataset, and how to identify the structure of
the data.

We discussed the importance of understanding the data we are working with, and
how to identify unexpected values in our data. We also discussed the importance
of data cleansing, and how to handle missing data and outliers.

However we source our datasets, it is essential we understand up front the
quality and limitations of the data we are working with. Evaluating datasets is
an essential part of the data analysis process; you will use these skills
throughout your data science career, whether you are quickly interrogating a
simple database table, or performing a deep dive into a complex dataset.

The steps in this week form a good foundation to any formal data analysis work,
whether you follow frameworks like CRISP-DM, PPDAC, or KDD.

---

## Activity 2.4.1

_Allow 30 minutes for this activity._

Reflect on the data you have worked with this week, post your thoughts in the
forum. What did you find challenging? What did you find interesting? What would
you like to learn more about?

---
