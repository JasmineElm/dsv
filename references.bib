@article{azevedoKDDSemmaCRISPDM2008,
  title = {{{KDD}}, Semma and {{CRISP-DM}}: {{A}} Parallel Overview},
  shorttitle = {{{KDD}}, {{Semma}} and {{CRISP-DM}}},
  author = {Azevedo, Ana and Santos, Manuel},
  year = {2008},
  month = jan,
  pages = {182--185},
  abstract = {In the last years there has been a huge growth and consolidation of the Data Mining field. Some efforts are being done that seek the establishment of standards in the area. Included on these efforts there can be enumerated SEMMA and CRISP-DM. Both grow as industrial standards and define a set of sequential steps that pretends to guide the implementation of data mining applications. The question of the existence of substantial differences between them and the traditional KDD process arose. In this paper, is pretended to establish a parallel between these and the KDD process as well as an understanding of the similarities between them.},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/azevedo_santos_2008_kdd,_semma_and_crisp-dm.pdf}
}

@book{bramerPrinciplesDataMining2016,
  title = {Principles of {{Data Mining}}},
  author = {Bramer, Max},
  year = {2016},
  series = {Undergraduate {{Topics}} in {{Computer Science}}},
  publisher = {Springer London},
  address = {London},
  doi = {10.1007/978-1-4471-7307-6},
  isbn = {978-1-4471-7306-9 978-1-4471-7307-6},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/bramer_2016_principles_of_data_mining.pdf;/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/bramer_2016_principles_of_data_mining2.pdf;/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/bramer_2016_principles_of_data_mining3.pdf}
}

@book{brandtDataAnalysis2014,
  title = {Data {{Analysis}}},
  author = {Brandt, Siegmund},
  year = {2014},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-03762-2},
  isbn = {978-3-319-03761-5 978-3-319-03762-2},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/brandt_2014_data_analysis.pdf;/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/brandt_2014_data_analysis2.pdf;/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/brandt_2014_data_analysis3.pdf}
}

@article{bronsonBigDataFood2016,
  title = {Big {{Data}} in Food and Agriculture},
  author = {Bronson, Kelly and Knezevic, Irena},
  year = {2016},
  month = jun,
  journal = {Big Data \& Society},
  volume = {3},
  number = {1},
  pages = {2053951716648174},
  publisher = {SAGE Publications Ltd},
  issn = {2053-9517},
  doi = {10/gcd2g5},
  abstract = {Farming is undergoing a digital revolution. Our existing review of current Big Data applications in the agri-food sector has revealed several collection and analytics tools that may have implications for relationships of power between players in the food system (e.g. between farmers and large corporations). For example, Who retains ownership of the data generated by applications like Monsanto Corproation's Weed I.D. ``app''? Are there privacy implications with the data gathered by John Deere's precision agricultural equipment? Systematically tracing the digital revolution in agriculture, and charting the affordances as well as the limitations of Big Data applied to food and agriculture, should be a broad research goal for Big Data scholarship. Such a goal brings data scholarship into conversation with food studies and it allows for a focus on the material consequences of big data in society.},
  langid = {english},
  keywords = {agribusiness,digital revolution in agriculture,farmers,material implications of big data,power},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/bronson_knezevic_2016_big_data_in_food_and_agriculture.pdf;/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/bronson_knezevic_2016_big_data_in_food_and_agriculture2.pdf}
}

@book{cairoTruthfulArtData2016,
  title = {The {{Truthful Art}}: {{Data}}, {{Charts}}, and {{Maps}} for {{Communication}}},
  shorttitle = {The {{Truthful Art}}},
  author = {Cairo, Alberto},
  year = {2016},
  month = feb,
  edition = {1 edition},
  publisher = {New Riders},
  address = {Place of publication not identified},
  abstract = {No matter what your actual job title, you are---or soon will be---a data worker.  Every day, at work, home, and school, we are bombarded with vast amounts of free data collected and shared by everyone and everything from our co-workers to our calorie counters. In this highly anticipated follow-up to The Functional Art---Alberto Cairo's foundational guide to understanding information graphics and visualization---the respected data visualization professor explains in clear terms how to work with data, discover the stories hidden within, and share those stories with the world in the form of charts, maps, and infographics. In The Truthful Art, Cairo transforms elementary principles of data and scientific reasoning into tools that you can use in daily life to interpret data sets and extract stories from them.      The Truthful Art explains:   {$\bullet$} The role infographics and data visualization play in our world {$\bullet$} Basic principles of data and scientific reasoning that anyone can master {$\bullet$} How to become a better critical thinker {$\bullet$} Step-by-step processes that will help you evaluate any data visualization (including your own) {$\bullet$} How to create and use effective charts, graphs, and data maps to explain data to any audience   The Truthful Art is also packed with inspirational and educational real-world examples of data visualizations from such leading publications as The New York Times, The Wall Street Journal, Estado de S{\~a}o Paulo (Brazil), Berliner Morgenpost (Germany), and many more.},
  isbn = {978-0-321-93407-9},
  langid = {english}
}

@book{guerreroExcelDataAnalysis2010,
  title = {Excel {{Data Analysis}}},
  author = {Guerrero, Hector},
  year = {2010},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-10835-8},
  isbn = {978-3-642-10834-1 978-3-642-10835-8},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/guerrero_2010_excel_data_analysis.pdf;/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/guerrero_2010_excel_data_analysis2.pdf}
}

@book{igualIntroductionDataScience2017,
  title = {Introduction to {{Data Science}}},
  author = {Igual, Laura and Segu{\'i}, Santi},
  year = {2017},
  series = {Undergraduate {{Topics}} in {{Computer Science}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-50017-1},
  isbn = {978-3-319-50016-4 978-3-319-50017-1},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/igual_seguí_2017_introduction_to_data_science.pdf;/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/igual_seguí_2017_introduction_to_data_science2.pdf}
}

@article{jensenDataSnoopingDredging2000,
  title = {Data {{Snooping}}, {{Dredging}} and {{Fishing}}: {{The Dark Side}} of {{Data Mining A SIGKDD99 Panel Report}}},
  author = {Jensen, David},
  year = {2000},
  pages = {4},
  doi = {10/bvf6gc},
  abstract = {This article briefly describes a panel discussion at SIGKDD99.},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/jensen_2000_data_snooping,_dredging_and_fishing.pdf;/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/jensen_2000_data_snooping,_dredging_and_fishing2.pdf}
}

@book{patilDataDriven2015,
  title = {Data {{Driven}}},
  author = {Patil, D. J. and Mason, Hilary},
  year = {2015},
  month = jan,
  edition = {1st edition},
  publisher = {O'Reilly Media},
  abstract = {Succeeding with data isn't just a matter of putting Hadoop in your machine room, or hiring some physicists with crazy math skills. It requires you to develop a data culture that involves people throughout the organization. In this O'Reilly report, DJ Patil and Hilary Mason outline the steps you need to take if your company is to be truly data-driven---including the questions you should ask and the methods you should adopt.You'll not only learn examples of how Google, LinkedIn, and Facebook use their data, but also how Walmart, UPS, and other organizations took advantage of this resource long before the advent of Big Data. No matter how you approach it, building a data culture is the key to success in the 21st century.You'll explore:Data scientist skills---and why every company needs a SpockHow the benefits of giving company-wide access to data outweigh the costsWhy data-driven organizations use the scientific method to explore and solve data problemsKey questions to help you develop a research-specific process for tackling important issuesWhat to consider when assembling your data teamDeveloping processes to keep your data team (and company) engagedChoosing technologies that are powerful, support teamwork, and easy to use and learn},
  langid = {english}
}

@misc{hillHowTargetFigured2012,
  title = {How {{Target Figured Out A Teen Girl Was Pregnant Before Her Father Did}}},
  author = {Hill, Kashmir},
  year = {2012},
  journal = {Forbes},
  urldate = {2024-06-28},
  abstract = {Target has perfected the technique of analyzing consumers' shopping habits to figure out who's pregnant. How can they send customers congratulatory coupons without freaking them out?},
  chapter = {Tech},
  howpublished = {https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/},
  langid = {english},
  file = {/Users/james/Zotero/storage/FHQ2KMF3/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did.html}
}

@article{duhiggHowCompaniesLearn2012,
  title = {How {{Companies Learn Your Secrets}}},
  author = {Duhigg, Charles},
  year = {2012},
  month = feb,
  journal = {The New York Times},
  issn = {0362-4331},
  urldate = {2024-06-28},
  abstract = {Your shopping habits reveal even the most personal information --- like when you're going to have a baby.},
  chapter = {Magazine},
  langid = {american},
  keywords = {Advertising and Marketing,Books and Literature,Brain,Columbia University,Consumer Behavior,Customer Relations,Data-Mining and Database Marketing,Massachusetts Institute of Technology,PREGNANCY AND OBSTETRICS,Privacy,Procter & Gamble Company,Psychology and Psychologists,Shopping and Retail,Smells and Odors,Statistics,Target Corporation,University of Alberta},
  file = {/Users/james/Zotero/storage/CMIWZT3W/shopping-habits.html}
}

@misc{piatetskyDidTargetReally2014,
  title = {Did {{Target Really Predict}} a {{Teen}}'s {{Pregnancy}}? {{The Inside Story}}},
  shorttitle = {Did {{Target Really Predict}} a {{Teen}}'s {{Pregnancy}}?},
  author = {Piatetsky, Gregory},
  year = {2014},
  month = may,
  journal = {KDNuggets},
  urldate = {2024-06-28},
  abstract = {We examine the origin and the facts behind this explosive story, the importance of headlines, and how unsubstantiated assumptions gain traction and mainstream attention and help create myths around Predictive Analytics.},
  chapter = {2014 May News, Features},
  howpublished = {https://www.kdnuggets.com/did-target-really-predict-a-teens-pregnancy-the-inside-story},
  langid = {american},
  file = {/Users/james/Zotero/storage/VNIU2NDX/target-predict-teen-pregnancy-inside-story.html}
}

@article{davenportDataScientistSexiest2012,
  title = {Data {{Scientist}}: {{The Sexiest Job}} of the 21st {{Century}}},
  shorttitle = {Data {{Scientist}}},
  author = {Davenport, Thomas H. and Patil, D. J.},
  year = {2012},
  month = oct,
  journal = {Harvard Business Review},
  issn = {0017-8012},
  urldate = {2024-06-28},
  abstract = {Back in the 1990s, computer engineer and Wall Street ``quant'' were the hot occupations in business. Today data scientists are the hires firms are competing to make. As companies wrestle with unprecedented volumes and types of information, demand for these experts has raced well ahead of supply. Indeed, Greylock Partners, the VC firm that backed Facebook and LinkedIn, is so worried about the shortage of data scientists that it has a recruiting team dedicated to channeling them to the businesses in its portfolio. Data scientists are the key to realizing the opportunities presented by big data. They bring structure to it, find compelling patterns in it, and advise executives on the implications for products, processes, and decisions. They find the story buried in the data and communicate it. And they don't just deliver reports: They get at the questions at the heart of problems and devise creative approaches to them. One data scientist who was studying a fraud problem, for example, realized it was analogous to a type of DNA sequencing problem. Bringing those disparate worlds together, he crafted a solution that dramatically reduced fraud losses. In this article, Harvard Business School's Davenport and Greylock's Patil take a deep dive on what organizations need to know about data scientists: where to look for them, how to attract and develop them, and how to spot a great one.},
  chapter = {Analytics and data science},
  keywords = {Analytics and data science,Data analysis,Data management,Data mining,EMC Corp.,Goldman Jonathan,Hiring and recruitment,Hoffman Reid 1967-,Information science,Klamka Jake,LinkedIn Corp.,Meta Platforms Inc.,North Carolina State University,Professional services,Roumeliotis George,Scientists},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/davenport_patil_2012_data_scientist.pdf;/Users/james/Zotero/storage/9PIG2KDS/data-scientist-the-sexiest-job-of-the-21st-century.html}
}

@misc{davenportDataScientistStill2022,
  title = {Is {{Data Scientist Still}} the {{Sexiest Job}} of the 21st {{Century}}?},
  author = {Davenport, Thomas H. and Patil, D. J.},
  year = {2022},
  month = sep,
  journal = {Tom Davenport},
  urldate = {2024-06-28},
  abstract = {Ten years ago, the authors posited that being a data scientist was the ``sexiest job [{\dots}]},
  langid = {american},
  file = {/Users/james/Zotero/storage/Q5L44C4Q/is-data-scientist-still-the-sexiest-job-of-the-21st-century.html}
}

@book{spiegelhalterArtStatisticsLearning2019,
  title = {The {{Art}} of {{Statistics}}: {{Learning}} from {{Data}}},
  shorttitle = {The {{Art}} of {{Statistics}}},
  author = {Spiegelhalter, David},
  year = {2019},
  month = mar,
  publisher = {Pelican},
  abstract = {'A statistical national treasure' Jeremy Vine, BBC Radio 2'Required reading for all politicians, journalists, medics and anyone who tries to influence people (or is influenced) by statistics. A tour de force' Popular ScienceDo busier hospitals have higher survival rates? How many trees are there on the planet? Why do old men have big ears? David Spiegelhalter reveals the answers to these and many other questions - questions that can only be addressed using statistical science.Statistics has played a leading role in our scientific understanding of the world for centuries, yet we are all familiar with the way statistical claims can be sensationalised, particularly in the media. In the age of big data, as data science becomes established as a discipline, a basic grasp of statistical literacy is more important than ever. In The Art of Statistics, David Spiegelhalter guides the reader through the essential principles we need in order to derive knowledge from data. Drawing on real world problems to introduce conceptual issues, he shows us how statistics can help us determine the luckiest passenger on the Titanic, whether serial killer Harold Shipman could have been caught earlier, and if screening for ovarian cancer is beneficial. 'Shines a light on how we can use the ever-growing deluge of data to improve our understanding of the world' Nature},
  langid = {english}
}

@book{nussbaumerknaflicStorytellingDataData2015,
  title = {Storytelling with {{Data}}: {{A Data Visualization Guide}} for {{Business Professionals}}},
  shorttitle = {Storytelling with {{Data}}},
  author = {Nussbaumer Knaflic, Cole},
  year = {2015},
  publisher = {John Wiley \& Sons, Incorporated},
  address = {Newark, UNITED STATES},
  urldate = {2024-06-28},
  abstract = {Don't simply show your data--tell a story with it! Storytelling with Data teaches you the fundamentals of data visualization and how to communicate effectively with data. You'll discover the power of storytelling and the way to make data a pivotal point in your story. The lessons in this illuminative text are grounded in theory, but made accessible through numerous real-world examples--ready for immediate application to your next graph or presentation. Storytelling is not an inherent skill, especially when it comes to data visualization, and the tools at our disposal don't make it any easier. This book demonstrates how to go beyond conventional tools to reach the root of your data, and how to use your data to create an engaging, informative, compelling story. Specifically, you'll learn how to: Understand the importance of context and audience Determine the appropriate type of graph for your situation Recognize and eliminate the clutter clouding your information Direct your audience's attention to the most important parts of your data Think like a designer and utilize concepts of design in data visualization Leverage the power of storytelling to help your message resonate with your audience Together, the lessons in this book will help you turn your data into high impact visual stories that stick with your audience. Rid your world of ineffective graphs, one exploding 3D pie chart at a time. There is a story in your data--Storytelling with Data will give you the skills and power to tell it!},
  isbn = {978-1-119-00206-2},
  keywords = {Information visualization},
  file = {/Users/james/Zotero/storage/9LN8HYZJ/detail.html}
}

@techreport{thefinancialcrisisinquirycommissionFINANCIALCRISISINQUIRY2011,
  title = {{{THE FINANCIAL CRISIS INQUIRY REPORT}}},
  author = {THE FINANCIAL CRISIS INQUIRY COMMISSION},
  year = {2011},
  urldate = {2024-06-30},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/the_financial_crisis_inquiry_commission_2011_the_financial_crisis_inquiry_report.pdf}
}

@misc{lioudisCollapseLehmanBrothers2024,
  title = {The {{Collapse}} of {{Lehman Brothers}}: {{A Case Study}}},
  shorttitle = {The {{Collapse}} of {{Lehman Brothers}}},
  author = {Lioudis, Nick},
  year = {2024},
  month = feb,
  journal = {Investopedia},
  urldate = {2024-06-30},
  abstract = {Lehman Brothers survived many financial crises in its long history until it was driven into bankruptcy. Learn more about the history behind this famous scandal.},
  howpublished = {https://www.investopedia.com/articles/economics/09/lehman-brothers-collapse.asp},
  langid = {english},
  file = {/Users/james/Zotero/storage/WZLTA6BN/lehman-brothers-collapse.html}
}

@misc{dpicampaignsTakeActionSustainable,
  title = {Take {{Action}} for the {{Sustainable Development Goals}}},
  author = {{dpicampaigns}},
  journal = {United Nations Sustainable Development},
  urldate = {2024-06-30},
  abstract = {United Nations Sustainable Development Goals - Time for Global Action for People and Planet},
  langid = {american},
  file = {/Users/james/Zotero/storage/YC6AID3I/sustainable-development-goals.html}
}

@book{chapagainHandsonWebScraping2019,
  title = {Hands-on Web Scraping with {{Python}}: Perform Advanced Scraping Operations Using Various {{Python}} Libraries and Tools Such as {{Selenium}}, {{Regex}}, and Others},
  shorttitle = {Hands-on Web Scraping with {{Python}}},
  author = {Chapagain, Anish},
  year = {2019},
  publisher = {Packt Publishing, Limited},
  address = {Birmingham},
  abstract = {Web scraping is an essential technique used in many organizations to scrape valuable data from web pages. This book will help you master web scraping techniques and methodologies using Python libraries and other popular tools such as Selenium. By the end of this book, you will have learned how to efficiently scrape different websites},
  isbn = {978-1-78953-339-2},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/chapagain_2019_hands-on_web_scraping_with_python.pdf}
}

@book{sahaDoingMathPython2015,
  title = {Doing Math with {{Python}}: Use Programming to Explore Algebra, Statistics, Calculus, and More!},
  shorttitle = {Doing Math with {{Python}}},
  author = {Saha, Amit},
  year = {2015},
  publisher = {No Starch Press},
  address = {San Francisco},
  abstract = {"Uses the Python programming language as a tool to explore high school level mathematics like statistics, geometry, probability, and calculus by writing programs to find derivatives, solve equations graphically, manipulate algebraic expressions, and examine projectile motion. Covers programming concepts including using functions, handling user input, and reading and manipulating data"--},
  isbn = {978-1-59327-640-9},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/saha_2015_doing_math_with_python.pdf}
}

@book{daleDataVisualizationPython2016,
  title = {Data Visualization with {{Python}} and {{JavaScript}}: Scrape, Clean, Explore \& Transform Your Data},
  shorttitle = {Data Visualization with {{Python}} and {{JavaScript}}},
  author = {Dale, Kyran},
  year = {2016},
  edition = {First edition},
  publisher = {O'Reilly Media, Inc},
  address = {Sebastopol, CA},
  isbn = {978-1-4919-2051-0},
  lccn = {QA76.9.I52 D35 2016},
  keywords = {Information visualization,JavaScript,JavaScript (Computer program language),Python,Python (Computer program language),Visualisierung},
  annotation = {OCLC: ocn919482330},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/dale_2016_data_visualization_with_python_and_javascript.pdf}
}

@book{janertDataAnalysisOpen2011,
  title = {Data Analysis with Open Source Tools: A Hands-on Guide for Programmers and Data Scientists},
  shorttitle = {Data Analysis with Open Source Tools},
  author = {Janert, Philipp K.},
  year = {2011},
  edition = {1. ed},
  publisher = {O'Reilly},
  address = {Beijing K{\"o}ln},
  isbn = {978-0-596-80235-6},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/janert_2011_data_analysis_with_open_source_tools.pdf}
}

@techreport{nelsonDefiningUnitedStates2020,
  title = {Defining the {{United States}} Land Base: A Technical Document Supporting the {{USDA Forest Service}} 2020 {{RPA}} Assessment},
  shorttitle = {Defining the {{United States}} Land Base},
  author = {Nelson, Mark D. and Riitters, Kurt H. and Coulston, John W. and Domke, Grant M. and Greenfield, Eric J. and Langner, Linda L. and Nowak, David J. and O'Dea, Claire B. and Oswalt, Sonja N. and Reeves, Matthew C. and Wear, David N.},
  year = {2020},
  number = {NRS-GTR-191},
  pages = {NRS-GTR-191},
  address = {Madison, WI},
  institution = {U.S. Department of Agriculture, Forest Service, Northern Research Station},
  doi = {10.2737/NRS-GTR-191},
  urldate = {2024-06-30},
  abstract = {The Resources Planning Act (RPA) Assessment incorporates social, economic, and biophysical dimensions into an assessment of renewable natural resources across the United States. The classification and representation of the land base of the United States in the RPA Assessment are fundamental to understanding how resource conditions, trends, and future projections are estimated and interpreted. Land use and land cover perspectives are both important and need to be described. Land use describes the social and economic intent for which land is used, while land cover describes the vegetation, exposed land surfaces, water, and artificial structures covering the land surface at a given time. The choice of one land classification system over another depends on several factors, including the specific resource question being addressed, the data available to answer the question, the time frame of the analysis, and the spatial extent of the study area.},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/nelson_et_al_2020_defining_the_united_states_land_base.pdf}
}

@article{brokawDBH2000,
  title = {The {{H}} for {{DBH}}},
  author = {Brokaw, Nicholas and Thompson, Jill},
  year = {2000},
  month = apr,
  journal = {Forest Ecology and Management},
  volume = {129},
  number = {1-3},
  pages = {89--91},
  issn = {03781127},
  doi = {10.1016/S0378-1127(99)00141-3},
  urldate = {2024-06-30},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  annotation = {78 citations (Semantic Scholar/DOI) [2024-06-30]},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/brokaw_thompson_2000_the_h_for_dbh.pdf}
}

@article{crowtherMappingTreeDensity2015,
  title = {Mapping Tree Density at a Global Scale},
  author = {Crowther, T. W. and Glick, H. B. and Covey, K. R. and Bettigole, C. and Maynard, D. S. and Thomas, S. M. and Smith, J. R. and Hintler, G. and Duguid, M. C. and Amatulli, G. and Tuanmu, M.-N. and Jetz, W. and Salas, C. and Stam, C. and Piotto, D. and Tavani, R. and Green, S. and Bruce, G. and Williams, S. J. and Wiser, S. K. and Huber, M. O. and Hengeveld, G. M. and Nabuurs, G.-J. and Tikhonova, E. and Borchardt, P. and Li, C.-F. and Powrie, L. W. and Fischer, M. and Hemp, A. and Homeier, J. and Cho, P. and Vibrans, A. C. and Umunay, P. M. and Piao, S. L. and Rowe, C. W. and Ashton, M. S. and Crane, P. R. and Bradford, M. A.},
  year = {2015},
  month = sep,
  journal = {Nature},
  volume = {525},
  number = {7568},
  pages = {201--205},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature14967},
  urldate = {2024-06-30},
  abstract = {Ground-sourced tree density data is assembled to provide a global map of tree density, which reveals that there are three trillion trees (tenfold more than previous estimates); tree numbers have declined by nearly half since the start of human civilization and over 15 billion trees are lost on an annual basis.},
  copyright = {2015 Springer Nature Limited},
  langid = {english},
  keywords = {Environmental sciences,Forest ecology,Forestry},
  annotation = {694 citations (Semantic Scholar/DOI) [2024-06-30]},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/crowther_et_al_2015_mapping_tree_density_at_a_global_scale2.pdf}
}

@book{silverSignalNoiseArt2013,
  title = {The {{Signal}} and the {{Noise}}: {{The Art}} and {{Science}} of {{Prediction}}},
  shorttitle = {The {{Signal}} and the {{Noise}}},
  author = {Silver, Nate},
  year = {2013},
  month = apr,
  edition = {1st edition},
  publisher = {Penguin},
  address = {London},
  abstract = {The International Bestseller by 'The Galileo of number crunchers' (Independent)Every time we choose a route to work, decide whether to go on a second date, or set aside money for a rainy day, we are making a prediction about the future. Yet from the financial crisis to ecological disasters, we routinely fail to foresee hugely significant events, often at great cost to society. The rise of 'big data' has the potential to help us predict the future, yet much of it is misleading, useless or distracting.In The Signal and the Noise, the New York Times political forecaster Nate Silver, who accurately predicted the results of every state in the 2012 US election, reveals how we can all develop better foresight in an uncertain world. From the stock market to the poker table, from earthquakes to the economy, he takes us on an enthralling insider's tour of the high-stakes world of forecasting, showing how we can all learn to detect the true signals amid a noise of data. 'Remarkable and rewarding' Matthew D'Ancona, Sunday Telegraph'A lucid explanation of how to think probabilistically' Guardian},
  isbn = {978-0-14-197565-8},
  langid = {english}
}

@book{zuboffAgeSurveillanceCapitalism2019,
  title = {The {{Age}} of {{Surveillance Capitalism}}: {{The Fight}} for a {{Human Future}} at the {{New Frontier}} of {{Power}}},
  shorttitle = {The {{Age}} of {{Surveillance Capitalism}}},
  author = {Zuboff, Professor Shoshana},
  year = {2019},
  month = sep,
  publisher = {Profile Books},
  address = {London},
  abstract = {THE TOP 10 SUNDAY TIMES BESTSELLER'Everyone needs to read this book as an act of digital self-defense.' - Naomi Klein, Author of No Logo, The Shock Doctrine, This Changes Everything and No is Not EnoughThe challenges to humanity posed by the digital future, the first detailed examination of the unprecedented form of power called "surveillance capitalism," and the quest by powerful corporations to predict and control us.The heady optimism of the Internet's early days is gone. Technologies that were meant to liberate us have deepened inequality and stoked divisions. Tech companies gather our information online and sell it to the highest bidder, whether government or retailer. Profits now depend not only on predicting our behaviour but modifying it too. How will this fusion of capitalism and the digital shape our values and define our future? Shoshana Zuboff shows that we are at a crossroads. We still have the power to decide what kind of world we want to live in, and what we decide now will shape the rest of the century. Our choices: allow technology to enrich the few and impoverish the many, or harness it and distribute its benefits.The Age of Surveillance Capitalism is a deeply-reasoned examination of the threat of unprecedented power free from democratic oversight. As it explores this new capitalism's impact on society, politics, business, and technology, it exposes the struggles that will decide both the next chapter of capitalism and the meaning of information civilization. Most critically, it shows how we can protect ourselves and our communities and ensure we are the masters of the digital rather than its slaves.},
  isbn = {978-1-78125-685-5},
  langid = {english}
}

@book{gutmanBecomingDataHead2021,
  title = {Becoming a {{Data Head}}: {{How}} to {{Think}}, {{Speak}}, and {{Understand Data Science}}, {{Statistics}}, and {{Machine Learning}}},
  shorttitle = {Becoming a {{Data Head}}},
  author = {Gutman, Alex J. and Goldmeier, Jordan},
  year = {2021},
  month = apr,
  publisher = {John Wiley \& Sons},
  abstract = {"Turn yourself into a Data Head. You'll become a more valuable employee and make your organization more successful."Thomas H. Davenport, Research Fellow, Author of Competing on Analytics, Big Data @ Work, and The AI Advantage You've heard the hype around data---now get the facts. In Becoming a Data Head: How to Think, Speak, and Understand Data Science, Statistics, and Machine Learning, award-winning data scientists Alex Gutman and Jordan Goldmeier pull back the curtain on data science and give you the language and tools necessary to talk and think critically about it. You'll learn how to:  Think statistically and understand the role variation plays in your life and decision making Speak intelligently and ask the right questions about the statistics and results you encounter in the workplace Understand what's really going on with machine learning, text analytics, deep learning, and artificial intelligence Avoid common pitfalls when working with and interpreting data  Becoming a Data Head is a complete guide for data science in the workplace: covering everything from the personalities you'll work with to the math behind the algorithms. The authors have spent years in data trenches and sought to create a fun, approachable, and eminently readable book. Anyone can become a Data Head---an active participant in data science, statistics, and machine learning. Whether you're a business professional, engineer, executive, or aspiring data scientist, this book is for you.},
  googlebooks = {GCUqEAAAQBAJ},
  isbn = {978-1-119-74176-3},
  langid = {english},
  keywords = {Business & Economics / Information Management,Business & Economics / Statistics,Computers / Data Science / Data Analytics,Computers / Desktop Applications / General,Computers / Information Technology}
}

@misc{anadiotisPlanetAnalyticsBig2017,
  title = {Planet Analytics: Big Data, Sustainability, and Environmental Impact},
  shorttitle = {Planet Analytics},
  author = {Anadiotis, George},
  year = {2017},
  month = apr,
  journal = {ZDNET},
  urldate = {2024-07-01},
  abstract = {What is the relation between big data applications and sustainability? What is the net effect of improved efficiency versus increased resource consumption, who gets to measure this, and how?},
  howpublished = {https://www.zdnet.com/article/planet-analytics-big-data-sustainability-and-environmental-impact/},
  langid = {english}
}

@book{shahHandsOnIntroductionData2020,
  title = {A {{Hands-On Introduction}} to {{Data Science}}},
  author = {Shah, Chirag},
  year = {2020},
  month = apr,
  publisher = {Cambridge University Press},
  abstract = {This book introduces the field of data science in a practical and accessible manner, using a hands-on approach that assumes no prior knowledge of the subject. The foundational ideas and techniques of data science are provided independently from technology, allowing students to easily develop a firm understanding of the subject without a strong technical background, as well as being presented with material that will have continual relevance even after tools and technologies change. Using popular data science tools such as Python and R, the book offers many examples of real-life applications, with practice ranging from small to big data. A suite of online material for both instructors and students provides a strong supplement to the book, including datasets, chapter slides, solutions, sample exams and curriculum suggestions. This entry-level textbook is ideally suited to readers from a range of disciplines wishing to build a practical, working knowledge of data science.},
  googlebooks = {L9XMDwAAQBAJ},
  isbn = {978-1-108-67390-7},
  langid = {english},
  keywords = {Business & Economics / General,Business & Economics / Knowledge Capital,Computers / Artificial Intelligence / General,Computers / Data Science / Data Analytics,Computers / Database Administration & Management,Computers / General},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/shah_2020_a_hands-on_introduction_to_data_science.pdf}
}

@misc{GoogleResponsibleAI,
  title = {Google {{Responsible AI Practices}}},
  journal = {Google AI},
  urldate = {2024-07-02},
  abstract = {Google AI is committed to developing and using artificial intelligence responsibly. We have a set of AI principles that guide our work, and we are transparent about how we develop and use AI. We also work to build trust with the public by engaging with policymakers, researchers, and other stakeholders.},
  howpublished = {https://ai.google/responsibility/responsible-ai-practices/},
  langid = {english},
  file = {/Users/james/Zotero/storage/HPEEJ8VL/responsible-ai-practices.html}
}

@article{gaoStatisticsMachineLearning2022,
  title = {Statistics and {{Machine Learning}} in {{Aviation Environmental Impact Analysis}}: {{A Survey}} of {{Recent Progress}}},
  shorttitle = {Statistics and {{Machine Learning}} in {{Aviation Environmental Impact Analysis}}},
  author = {Gao, Zhenyu and Mavris, Dimitri},
  year = {2022},
  month = nov,
  journal = {Aerospace},
  volume = {9},
  pages = {750},
  doi = {10.3390/aerospace9120750},
  abstract = {The rapid growth of global aviation operations has made its negative environmental impact an international concern. Accurate modeling of aircraft fuel burn, emissions, and noise is the prerequisite for informing new operational procedures, technologies, and policies towards a more sustainable future of aviation. In the past decade, due to the advances in big data technologies and effective algorithms, the transformative data-driven analysis has begun to play a substantial role in aviation environmental impact analysis. The integration of statistical and machine learning methods in the workflow has made such analysis more efficient and accurate. Through summarizing and classifying the representative works in this intersection area, this survey paper aims to extract prevailing research trends and suggest research opportunities for the future. The methodology overview section presents a comprehensive development process and landscape of statistical and machine learning methods for applied researchers. In the main section, relevant works in the literature are organized into seven application themes: data reduction, efficient computation, predictive modeling, uncertainty quantification, pattern discovery, verification and validation, and infrastructure and tools. Each theme contains background information, in-depth discussion, and a summary of representative works. The paper concludes with the proposal of five future opportunities for this research area.},
  annotation = {13 citations (Semantic Scholar/DOI) [2024-07-02]},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/gao_mavris_2022_statistics_and_machine_learning_in_aviation_environmental_impact_analysis.pdf}
}

@article{schroerSystematicLiteratureReview2021,
  title = {A {{Systematic Literature Review}} on {{Applying CRISP-DM Process Model}}},
  author = {Schr{\"o}er, Christoph and Kruse, Felix and G{\'o}mez, Jorge Marx},
  year = {2021},
  month = jan,
  journal = {Procedia Computer Science},
  series = {{{CENTERIS}} 2020 - {{International Conference}} on {{ENTERprise Information Systems}} / {{ProjMAN}} 2020 - {{International Conference}} on {{Project MANagement}} / {{HCist}} 2020 - {{International Conference}} on {{Health}} and {{Social Care Information Systems}} and {{Technologies}} 2020, {{CENTERIS}}/{{ProjMAN}}/{{HCist}} 2020},
  volume = {181},
  pages = {526--534},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2021.01.199},
  urldate = {2024-07-02},
  abstract = {CRISP-DM is the de-facto standard and an industry-independent process model for applying data mining projects. Twenty years after its release in 2000, we would like to provide a systematic literature review of recent studies published in IEEE, ScienceDirect and ACM about data mining use cases applying CRISP-DM. We give an overview of the research focus, current methodologies, best practices and possible gaps in conducting the six phases of CRISP-DM. The main findings are that CRISP-DM is still a de-factor standard in data mining, but there are challenges since the most studies do not foresee a deployment phase. The contribution of our paper is to identify best practices and process phases in which data mining analysts can be better supported. Further contribution is a template for structuring and releasing CRISP-DM studies.},
  keywords = {CRISP-DM,Data Mining,Deployment,Literature Review,Process Methodology},
  annotation = {212 citations (Semantic Scholar/DOI) [2024-07-02]},
  file = {/Users/james/Zotero/storage/M9I6RHDF/S1877050921002416.html}
}

@inproceedings{chapmanCRISPDMStepbystepData2000,
  title = {{{CRISP-DM}} 1.0: {{Step-by-step}} Data Mining Guide},
  shorttitle = {{{CRISP-DM}} 1.0},
  author = {Chapman, P.},
  year = {2000},
  urldate = {2024-07-02},
  abstract = {This document describes the CRISP-DM process model, including an introduction to the CRISP-DM methodology, the CRISP-DM reference model, the CRISP-DM user guide and the CRISP-DM reports, as well as an appendix with additional useful and related information. This document and information herein, are the exclusive property of the partners of the CRISP-DM All trademarks and service marks mentioned in this document are marks of their respective owners and are as such acknowledged by the members of the CRISP-DM consortium. Foreword CRISP-DM was conceived in late 1996 by three " veterans " of the young and immature data mining market. DaimlerChrysler (then Daimler-Benz) was already experienced, ahead of most industrial and commercial organizations, in applying data mining in its business operations. SPSS (then ISL) had been providing services based on data mining since 1990 and had launched the first commercial data mining workbench -- Clementine -- in 1994. NCR, as part of its aim to deliver added value to its Teradata data warehouse customers, had established teams of data mining consultants and technology specialists to service its clients' requirements. At that time, early market interest in data mining was showing signs of exploding into widespread uptake. This was both exciting and terrifying. All of us had developed our approaches to data mining as we went along. Were we doing it right? Was every new adopter of data mining going to have to learn, as we had initially, by trial and error? And from a supplier's perspective, how could we demonstrate to prospective customers that data mining was sufficiently mature to be adopted as a key part of their business processes? A standard process model, we reasoned, non-proprietary and freely available, would address these issues for us and for all practitioners. A year later we had formed a consortium, invented an acronym (CRoss-Industry Standard Process for Data Mining), obtained funding from the European Commission and begun to set out our initial ideas. As CRISP-DM was intended to be industry-, tool-and application-neutral, we knew we had to get input from as wide a range as possible of practitioners and others (such as data warehouse vendors and management consultancies) with a vested interest in data mining. We did this by creating the CRISP-DM Special Interest Group (" The SIG " , as it became known). We launched the SIG by broadcasting an invitation to interested parties to join us in Amsterdam for a day-long {\dots}},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/chapman_2000_crisp-dm_1.pdf}
}

@inproceedings{birkCommunicatingDataExploration2022,
  title = {Communicating Data Exploration Insights through Posters -{{A}} Preliminary Analysis of Primary Students{\textasciiacute} Learning Outcomes},
  booktitle = {Twelfth {{Congress}} of the {{European Society}} for {{Research}} in {{Mathematics Education}} ({{CERME12}})},
  author = {Birk, Lisa and Frischemeier, Daniel},
  year = {2022},
  month = feb,
  series = {Twelfth {{Congress}} of the {{European Society}} for {{Research}} in {{Mathematics Education}} ({{CERME12}})},
  volume = {TWG05},
  address = {Bozen-Bolzano, Italy},
  urldate = {2024-07-03},
  abstract = {Since data and its representations have gained a significant role in our society, mathematics education has to adapt by finding ways of teaching students statistical literacy from primary school onwards. In a teaching unit that was designed as part of a bachelor{\textasciiacute}s thesis, students of a fourth grade (10 to 11 years old) were introduced to group comparisons with the help of TinkerPlots and asked to create posters on statistical mini-projects. This paper aims at providing first ideas for a framework for the analysis of such means of communication to understand what results the young students communicate and how they do so. The posters show that the primary school pupils already employ not only local perspectives but utilize more global views to interpret the data.},
  keywords = {Data exploration,group comparisons,poster presentations},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/birk_frischemeier_2022_communicating_data_exploration_insights_through_posters_-a_preliminary_analysis.pdf}
}

@misc{statistics.gov.scotHelpWorkingMultidimensional,
  title = {Help: {{Working}} with Multidimensional Data},
  author = {{statistics.gov.scot}},
  journal = {Scottish Government},
  urldate = {2024-07-03},
  howpublished = {https://statistics.gov.scot/help/data\_cubes},
  file = {/Users/james/Zotero/storage/5TUZR6RS/data_cubes.html}
}

@book{beighleyHeadFirstSQL2007,
  title = {Head First {{SQL}}},
  author = {Beighley, Lynn},
  year = {2007},
  series = {Head First Series},
  publisher = {O'Reilly Media},
  address = {Beijing ; Sebastopol, CA},
  isbn = {978-0-596-52684-9},
  langid = {english},
  lccn = {QA76.73.S67 B435 2007},
  keywords = {SQL (Computer program language),SQL (Langage de programmation)},
  annotation = {OCLC: ocn170956332},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/beighley_2007_head_first_sql.pdf}
}

@article{holmUnderstandingStatistics,
  title = {Understanding {{Statistics}}},
  author = {Holm, Sture},
  journal = {UNDERSTANDING STATISTICS},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/holm_understanding_statistics.pdf}
}

@book{molinaroSQLCookbookQuery2006,
  title = {{{SQL}} Cookbook: Query Solutions and Techniques for Database Developers ; Covers {{SQL}} Server, {{PostgerSQL}}, {{Oracle}}, {{MySQL}}, and {{DB2}}},
  shorttitle = {{{SQL}} Cookbook},
  author = {Molinaro, Anthony},
  year = {2006},
  edition = {1. ed},
  publisher = {O'Reilly},
  address = {Beijing K{\"o}ln},
  isbn = {978-0-596-00976-2},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/molinaro_2006_sql_cookbook.pdf}
}

@book{weigendDataPeopleHow2017,
  title = {Data for the {{People}}: {{How}} to {{Make Our Post-Privacy Economy Work}} for {{You}}},
  shorttitle = {Data for the {{People}}},
  author = {Weigend, Andreas},
  year = {2017},
  month = jan,
  publisher = {Basic Books},
  abstract = {A long-time chief data scientist at Amazon shows how open data can make everyone, not just corporations, richer Every time we Google something, Facebook someone, Uber somewhere, or even just turn on a light, we create data that businesses collect and use to make decisions about us. In many ways this has improved our lives, yet, we as individuals do not benefit from this wealth of data as much as we could. Moreover, whether it is a bank evaluating our credit worthiness, an insurance company determining our risk level, or a potential employer deciding whether we get a job, it is likely that this data will be used against us rather than for us. In Data for the People, Andreas Weigend draws on his years as a consultant for commerce, education, healthcare, travel and finance companies to outline how Big Data can work better for all of us. As of today, how much we benefit from Big Data depends on how closely the interests of big companies align with our own. Too often, outdated standards of control and privacy force us into unfair contracts with data companies, but it doesn't have to be this way. Weigend makes a powerful argument that we need to take control of how our data is used to actually make it work for us. Only then can we the people get back more from Big Data than we give it. Big Data is here to stay. Now is the time to find out how we can be empowered by it.},
  googlebooks = {ACjXCwAAQBAJ},
  isbn = {978-0-465-09653-4},
  langid = {english},
  keywords = {Computers / Internet / General,Computers / Internet / Online Safety & Privacy,Science / System Theory}
}

@book{gurinOpenDataNow2014,
  title = {Open Data Now : The Secret to Hot Startups, Smart Investing, Savvy Marketing, and Fast Innovation},
  shorttitle = {Open Data Now},
  author = {Gurin, Joel},
  year = {2014},
  publisher = {New York : McGraw-Hill Education},
  urldate = {2024-07-06},
  abstract = {xvi, 330 pages ; 23 cm; Includes bibliographical references (pages 275-312) and index},
  collaborator = {{Internet Archive}},
  isbn = {978-0-07-182977-9},
  langid = {english},
  keywords = {Statistical services}
}

@book{doyleAdventureCopperBeeches1986,
  title = {The {{Adventure}} of the {{Copper Beeches}}},
  author = {Doyle, Arthur Conan},
  year = {1986},
  publisher = {World International Publishing},
  abstract = {Arthur Conan Doyle's Sherlock Holmes is perhaps the world's most famous detective. The 'Focus on Sherlock Holmes' series is devoted to bringing the books to an even wider audience. George Cavendish has added explanations as footnotes to help those readers who are not familiar with some of the phrases used by the author and his characters - after all the stories were written over 120 years ago. Some of the author's phrases are still in use in modern-day British English and these are described to make the text clearer to English speakers from outside of the UK, or to those who do not speak English as a first language. Also included is some background information on places, names and terms used in the story. The book features the original drawings from the first publication.},
  googlebooks = {HO0yvk0FKiQC},
  isbn = {978-0-7235-7829-1},
  langid = {english},
  keywords = {Fiction / Mystery & Detective / Traditional}
}

@book{mccandlessInformationBeautiful2012,
  title = {Information Is {{Beautiful}}},
  author = {McCandless, David},
  year = {2012},
  month = dec,
  edition = {Reprint edition},
  publisher = {Collins},
  address = {London},
  abstract = {A visual guide to how the world really works, through stunning infographics and data visualisations, thoroughly revised, recalculated and reimagined for this new edition.We are overwhelmed by information -- from our phones, our televisions, our computers, our newspapers.This new edition of Information is Beautiful has been revised throughout with over 20 updates and 20 new visualisations. It offers shelter from the flood by visualising data in a new way that blends facts with their connections, their context and their relationships -- making information meaningful, entertaining and beautiful.This is information like you have never seen it before -- easy to flick through but also engaging enough to study -- information that comes to life in your hands and your eyes.},
  isbn = {978-0-00-749289-3},
  langid = {english}
}

@book{rogersFactsAreSacred2013,
  title = {Facts Are {{Sacred}}},
  author = {Rogers, Simon},
  year = {2013},
  month = apr,
  edition = {Main edition},
  publisher = {Guardian Faber Publishing},
  address = {London},
  abstract = {What is the true human cost of the war in Afghanistan? What are the real effects of the austerity measure? And how did the London riots spread so quickly?Facts are Sacred, the Guardian's award-winning datablog, publishes and analyses seemingly benign data - released under the auspices of transparency - to bring its readers astonishing revelations about the way we live now. It reveals how data has changed our world and what we can learn from it. Now, the most telling findings from the blog are brought together to give us the facts and figures behind the headlines, beautifully illustrated with extensive data visualisations. Ground-breaking and fascinating, it celebrates a resource that has pushed the boundaries of modern journalism and is a manifesto for a new way of seeing things.},
  isbn = {978-0-571-30161-4},
  langid = {english}
}

@book{kirkDataVisualisationHandbook2016,
  title = {Data {{Visualisation}}: {{A Handbook}} for {{Data Driven Design}}},
  shorttitle = {Data {{Visualisation}}},
  author = {Kirk, Andy},
  year = {2016},
  month = jul,
  edition = {First Edition},
  publisher = {SAGE Publications Ltd},
  address = {Los Angeles},
  abstract = {Voted one of the "six best books for data geeks"~by The Financial Times. Read the review here.  Lecturers, request your~electronic inspection copy.  Never has it been more essential to work in the world of data. Scholars and students need to be able to analyze, design, and curate information into useful tools of communication, insight, and understanding. This book is the starting point in learning the process and skills of data visualization, teaching the concepts and skills of how to present data, and inspiring effective visual design.  Benefits of this book:A flexible step-by-step journey that equips you to achieve great data visualizationA curated collection of classic and contemporary examples, giving illustrations of good and bad practiceExamples on every page to give creative inspirationIllustrations of good and bad practice show you how to critically evaluate and improve your own workAdvice and experience from the best designers in the fieldLoads of online practical help, checklists, case studies and exercises make this the most comprehensive text available},
  isbn = {978-1-4739-1213-7},
  langid = {english}
}

@book{demauroDataAnalyticsMade2021,
  title = {Data Analytics Made Easy: Analyze and Present Data to Make Informed Decisions without Writing Any Code},
  shorttitle = {Data Analytics Made Easy},
  author = {De Mauro, Andrea},
  year = {2021},
  series = {Expert Insight},
  publisher = {Packt},
  address = {Birmingham Mumbai},
  isbn = {978-1-80107-415-5},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/de_mauro_2021_data_analytics_made_easy2.pdf}
}

@book{georgePracticalDataScience2021,
  title = {Practical Data Science with {{Python}}: Learn Tools and Techniques from Hands-on Examples to Extract Insights from Data},
  shorttitle = {Practical Data Science with {{Python}}},
  author = {George, Nathan},
  year = {2021},
  series = {Expert Insight},
  publisher = {Packt},
  address = {Birmingham Mumbai},
  isbn = {978-1-80107-197-0},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/george_2021_practical_data_science_with_python2.pdf}
}

@article{mertzCleaningDataEffective,
  title = {Cleaning {{Data}} for {{Effective Data Science}}},
  author = {Mertz, David},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/mertz_cleaning_data_for_effective_data_science.pdf}
}

@misc{phamPredictiveModelingMovements2022,
  title = {Predictive Modeling of Movements of Refugees and Internally Displaced People: {{Towards}} a Computational Framework},
  shorttitle = {Predictive Modeling of Movements of Refugees and Internally Displaced People},
  author = {Pham, Katherine Hoffmann and {Luengo-Oroz}, Miguel},
  year = {2022},
  month = jan,
  number = {arXiv:2201.08006},
  eprint = {2201.08006},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-07-07},
  abstract = {Predicting forced displacement is an important undertaking of many humanitarian aid agencies, which must anticipate flows in advance in order to provide vulnerable refugees and Internally Displaced Persons (IDPs) with shelter, food, and medical care. While there is a growing interest in using machine learning to better anticipate future arrivals, there is little standardized knowledge on how to predict refugee and IDP flows in practice. Researchers and humanitarian officers are confronted with the need to make decisions about how to structure their datasets and how to fit their problem to predictive analytics approaches, and they must choose from a variety of modeling options. Most of the time, these decisions are made without an understanding of the full range of options that could be considered, and using methodologies that have primarily been applied in different contexts -- and with different goals -- as opportunistic references. In this work, we attempt to facilitate a more comprehensive understanding of this emerging field of research by providing a systematic model-agnostic framework, adapted to the use of big data sources, for structuring the prediction problem. As we do so, we highlight existing work on predicting refugee and IDP flows. We also draw on our own experience building models to predict forced displacement in Somalia, in order to illustrate the choices facing modelers and point to open research questions that may be used to guide future work.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computers and Society},
  annotation = {12 citations (Semantic Scholar/arXiv) [2024-07-07]},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/pham_luengo-oroz_2022_predictive_modeling_of_movements_of_refugees_and_internally_displaced_people.pdf}
}

@article{koltayDataLiteracyResearchers2017,
  title = {Data Literacy for Researchers and Data Librarians},
  author = {Koltay, Tibor},
  year = {2017},
  month = mar,
  journal = {Journal of Librarianship and Information Science},
  volume = {49},
  number = {1},
  pages = {3--14},
  publisher = {SAGE Publications Ltd},
  issn = {0961-0006},
  doi = {10.1177/0961000615616450},
  urldate = {2024-07-07},
  abstract = {This paper describes data literacy and emphasizes its importance. Data literacy is vital for researchers who need to become data literate science workers and also for (potential) data management professionals. Its important characteristic is a close connection and similarity to information literacy. To support this argument, a review of literature was undertaken on the importance of data, and the data-intensive paradigm of scientific research, researchers' expected and real behaviour, the nature of research data management, the possible roles of the academic library, data quality and data citation, Besides describing the nature of data literacy and enumerating the related skills, the application of phenomenographic approaches to data literacy and its relationship to the digital humanities have been identified as subjects for further investigation.},
  langid = {english},
  annotation = {121 citations (Semantic Scholar/DOI) [2024-07-07]},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/koltay_2017_data_literacy_for_researchers_and_data_librarians.pdf}
}

@book{daviesStateOpenData2019,
  title = {The {{State}} of {{Open Data}}: {{Histories}} and {{Horizons}}},
  shorttitle = {The {{State}} of {{Open Data}}},
  author = {Davies, Tim and Walker, Stephen B and Rubinstein, Mor and Perini, Fernando},
  year = {2019},
  month = may,
  publisher = {{African Minds and IDRC}},
  doi = {10.47622/9781928331957},
  urldate = {2024-07-23},
  abstract = {Its been ten years since open data first broke onto the global stage. Over the past decade, thousands of programmes and projects around the world have worked to open data and use it to address a myriad of social and economic challenges. Meanwhile, issues related to data rights and privacy have moved to the centre of public and political discourse. As the open data movement enters a new phase in its evolution, shifting to target real-world problems and embed open data thinking into other existing or emerging communities of practice, big questions still remain. How will open data initiatives respond to new concerns about privacy, inclusion, and artificial intelligence? And what can we learn from the last decade in order to deliver impact where it is most needed?               The State of Open Data               brings together over 60 authors from around the world to address these questions and to take stock of the real progress made to date across sectors and around the world, uncovering the issues that will shape the future of open data in the years to come.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  isbn = {978-1-928331-95-7},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/davies_et_al_2019_the_state_of_open_data.pdf}
}

@misc{BuildingOpenData,
  title = {Building an Open Data Cloud Ecosystem},
  journal = {Google Cloud Blog},
  urldate = {2024-07-23},
  abstract = {A robust Data Cloud ecosystem lets you use all your data, from all sources, in all storage formats and styles of analysis, across all cloud providers.},
  howpublished = {https://cloud.google.com/blog/products/data-analytics/building-most-open-data-cloud-all-data-all-source-any-platform},
  langid = {american},
  file = {/Users/james/Zotero/storage/AI3QWQKC/building-most-open-data-cloud-all-data-all-source-any-platform.html}
}

@misc{gunnStepDataExploration2022,
  title = {Step 1 in the {{Data Exploration Journey}}: {{Getting Oriented}}, {{Nightingale}}},
  shorttitle = {Step 1 in the {{Data Exploration Journey}}},
  author = {Gunn, Erica},
  year = {2022},
  month = mar,
  journal = {Nightingale},
  urldate = {2024-07-23},
  abstract = {This article is part II in a series on data exploration, and the common struggles that we all face when trying to learn something new.},
  langid = {american},
  file = {/Users/james/Zotero/storage/I69TE5DI/data-exploration-step-1-getting-to-know-your-data.html}
}

@book{demauroDataAnalyticsMade2021a,
  title = {Data Analytics Made Easy: Analyze and Present Data to Make Informed Decisions without Writing Any Code},
  shorttitle = {Data Analytics Made Easy},
  author = {De Mauro, Andrea},
  year = {2021},
  series = {Expert Insight},
  publisher = {Packt},
  address = {Birmingham Mumbai},
  isbn = {978-1-80107-415-5},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/de_mauro_2021_data_analytics_made_easy.pdf}
}

@book{georgePracticalDataScience2021a,
  title = {Practical Data Science with {{Python}}: Learn Tools and Techniques from Hands-on Examples to Extract Insights from Data},
  shorttitle = {Practical Data Science with {{Python}}},
  author = {George, Nathan},
  year = {2021},
  series = {Expert Insight},
  publisher = {Packt},
  address = {Birmingham Mumbai},
  isbn = {978-1-80107-197-0},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/george_2021_practical_data_science_with_python.pdf}
}

@book{mertzCleaningDataEffective2021,
  title = {Cleaning Data for Effective Data Science: Doing the Other 80\% of the Work with {{Python}}, {{R}}, and Command-Line Tools},
  shorttitle = {Cleaning Data for Effective Data Science},
  author = {Mertz, David},
  year = {2021},
  publisher = {Packt Publishing Limited},
  address = {S.l.},
  abstract = {A comprehensive guide for data scientists to master effective data cleaning tools and techniques Key Features Master data cleaning techniques in a language-agnostic manner Learn from intriguing hands-on examples from numerous domains, such as biology, weather data, demographics, physics, time series, and image processing Work with detailed, commented, well-tested code samples in Python and R Book Description It is something of a truism in data science, data analysis, or machine learning that most of the effort needed to achieve your actual purpose lies in cleaning your data. Written in David's signature friendly and humorous style, this book discusses in detail the essential steps performed in every production data science or data analysis pipeline and prepares you for data visualization and modeling results. The book dives into the practical application of tools and techniques needed for data ingestion, anomaly detection, value imputation, and feature engineering. It also offers long-form exercises at the end of each chapter to practice the skills acquired. You will begin by looking at data ingestion of data formats such as JSON, CSV, SQL RDBMSes, HDF5, NoSQL databases, files in image formats, and binary serialized data structures. Further, the book provides numerous example data sets and data files, which are available for download and independent exploration. Moving on from formats, you will impute missing values, detect unreliable data and statistical anomalies, and generate synthetic features that are necessary for successful data analysis and visualization goals. By the end of this book, you will have acquired a firm understanding of the data cleaning process necessary to perform real-world data science and machine learning tasks. What you will learn How to think carefully about your data and ask the right questions Identify problem data pertaining to individual data points Detect problem data in the systematic "shape" of the data Remediate data integrity and hygiene problems Prepare data for analytic and machine learning tasks Impute values into missing or unreliable data Generate synthetic features that are more amenable to data science, data analysis, or visualization goals. Who this book is for This book is designed to benefit software developers, data scientists, aspiring data scientists, and students who are interested in data analysis or scientific computing. Basic familiarity with statistics, general concepts in machine learning,..},
  isbn = {978-1-80107-440-7},
  langid = {english},
  annotation = {OCLC: 1244742334},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/mertz_2021_cleaning_data_for_effective_data_science.pdf}
}

@book{qureshiSNOWFLAKECOOKBOOKRecipes2021,
  title = {{{SNOWFLAKE COOKBOOK}} Recipes for Building Modern Data Warehousing Solutions and Cloud Analytics... for Scalable Business Needs},
  author = {QURESHI, HAMMAD, HAMID SHARIF},
  year = {2021},
  publisher = {PACKT PUBLISHING LIMITED},
  address = {S.l.},
  isbn = {978-1-80056-018-5},
  langid = {english},
  annotation = {OCLC: 1240282615},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/qureshi_2021_snowflake_cookbook_recipes_for_building_modern_data_warehousing_solutions_and.pdf;/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/qureshi_2021_snowflake_cookbook_recipes_for_building_modern_data_warehousing_solutions_and2.pdf}
}

@article{friendlyEarlyOriginsDevelopment2005,
  title = {The Early Origins and Development of the Scatterplot},
  author = {Friendly, Michael and Denis, Daniel},
  year = 2005,
  journal = {Journal of the History of the Behavioral Sciences},
  volume = {41},
  number = {2},
  pages = {103--130},
  issn = {0022-5061, 1520-6696},
  doi = {10.1002/jhbs.20078},
  urldate = {2024-07-31},
  copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/friendly_denis_2005_the_early_origins_and_development_of_the_scatterplot.pdf}
}

@article{bionHowHelpsAirbnb2018,
  title = {How {{R Helps Airbnb Make}} the {{Most}} of Its {{Data}}},
  author = {Bion, Ricardo and Chang, Robert and Goodman, Jason},
  year = {2018},
  month = jan,
  journal = {The American Statistician},
  volume = {72},
  number = {1},
  pages = {46--52},
  publisher = {Taylor \& Francis},
  issn = {0003-1305},
  doi = {10.1080/00031305.2017.1392362},
  urldate = {2024-07-31},
  abstract = {At Airbnb, R has been among the most popular tools for doing data science work in many different contexts, including generating product insights, interpreting experiments, and building predictive models. Airbnb supports R usage by creating internal R tools and by creating a community of R users. We provide some specific advice for practitioners who wish to incorporate R into their day-to-day workflow.},
  keywords = {Exploratory data analysis,Inference,Machine learning,Statistical computing},
  annotation = {7 citations (Semantic Scholar/DOI) [2024-07-31]},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/bion_et_al_2018_how_r_helps_airbnb_make_the_most_of_its_data.pdf}
}

@article{lewisUKGovernmentUsing2020,
  title = {{{UK}} Government Using Confidential Patient Data in Coronavirus Response},
  author = {Lewis, Paul and Conn, David and Pegg, David},
  year = {2020},
  month = apr,
  journal = {The Guardian},
  issn = {0261-3077},
  urldate = {2024-08-02},
  abstract = {Exclusive: Documents seen by Guardian show tech firms using information to build `Covid-19 datastore'},
  chapter = {World news},
  langid = {british},
  keywords = {Coronavirus,Data protection,Health,Health policy,NHS,Politics,Privacy,Society,Technology,UK news},
  file = {/Users/james/Zotero/storage/P977SY3S/uk-government-using-confidential-patient-data-in-coronavirus-response.html}
}

@article{bannerNHSDataBreaches2022,
  title = {{{NHS}} Data Breaches: A Further Erosion of Trust},
  shorttitle = {{{NHS}} Data Breaches},
  author = {Banner, Natalie},
  year = {2022},
  month = may,
  journal = {BMJ},
  pages = {o1187},
  issn = {1756-1833},
  doi = {10.1136/bmj.o1187},
  urldate = {2024-08-02},
  langid = {english},
  annotation = {5 citations (Semantic Scholar/DOI) [2024-08-02]},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/banner_2022_nhs_data_breaches.pdf}
}

@misc{GeneralPracticeData,
  title = {General {{Practice Data}} for {{Planning}} and {{Research}} ({{GPDPR}})},
  journal = {NHS England Digital},
  urldate = {2024-08-02},
  abstract = {NHS Digital's\&nbsp;daily collection of GP data will\&nbsp;provide\&nbsp;data to\&nbsp;support vital health and care planning and research.\&nbsp;selling, data,\&nbsp;opt,\&nbsp;out,\&nbsp;23 june, sale, being,\&nbsp;sold, gpdpr,\&nbsp;general practice for planning and research, Type 1,\&nbsp;sell my, form,\&nbsp;gp, sharing, opting,\&nbsp;collecting,\&nbsp;Your optout,\&nbsp;scrape,\&nbsp;personal medical records, government collection,\&nbsp;website,\&nbsp;information, patient,\&nbsp;uk, sells,\&nbsp;database,\&nbsp;gpad,\&nbsp;guidance, england,\&nbsp;share},
  howpublished = {https://digital.nhs.uk/data-and-information/data-collections-and-data-sets/data-collections/general-practice-data-for-planning-and-research},
  langid = {english}
}

@misc{kazmaierBuildingOpenData2022,
  title = {Building an Open Data Cloud Ecosystem},
  author = {Kazmaier, Gerrit},
  year = {2022},
  month = oct,
  journal = {Google Cloud Blog},
  urldate = {2024-08-02},
  abstract = {A robust Data Cloud ecosystem lets you use all your data, from all sources, in all storage formats and styles of analysis, across all cloud providers.},
  howpublished = {https://cloud.google.com/blog/products/data-analytics/building-most-open-data-cloud-all-data-all-source-any-platform},
  langid = {american},
  file = {/Users/james/Zotero/storage/FH5TDKMS/building-most-open-data-cloud-all-data-all-source-any-platform.html}
}

@misc{harbertTappingPowerUnstructured2024,
  title = {Tapping the Power of Unstructured Data {\textbar} {{MIT Sloan}}},
  author = {Harbert, Tam},
  year = {2024},
  month = aug,
  journal = {MIT Sloan},
  urldate = {2024-08-02},
  abstract = {There's competitive advantage buried in text, images, audio, social media, and more --- as industries like shipping, retail, legal, and finance are finding.},
  howpublished = {https://mitsloan.mit.edu/ideas-made-to-matter/tapping-power-unstructured-data},
  langid = {english}
}

@misc{datapace16InnovativeApplications2018,
  title = {16 {{Innovative Applications}} and {{Businesses Created With Open Data}}},
  author = {Datapace},
  year = {2018},
  month = sep,
  journal = {Datapace},
  urldate = {2024-08-02},
  abstract = {Flying Cloud was a clipper ship that held world's sailing record over 100 years, from 1854 to 1989, for the fastest passage between New{\dots}},
  langid = {english},
  file = {/Users/james/Zotero/storage/DJVPJIM6/16-innovative-applications-and-businesses-created-with-open-data-9927c953e9d2.html}
}

@article{MatthewFontaineMaury1889,
  title = {Matthew {{Fontaine Maury}}},
  year = {1889},
  month = jan,
  journal = {The Atlantic},
  issn = {2151-9463},
  urldate = {2024-08-02},
  abstract = {None},
  langid = {english},
  file = {/Users/james/Zotero/storage/YZUWIUBK/634025.html}
}

@misc{stongeScientistSeasLegacy2018,
  title = {Scientist of the {{Seas}}: {{The Legacy}} of {{Matthew Fontaine Maury}} {\textbar} {{Worlds Revealed}}},
  author = {St Onge, Tim},
  year = {2018},
  urldate = {2024-08-02},
  howpublished = {https://blogs.loc.gov/maps/2018/07/scientist-of-the-seas-the-legacy-of-matthew-fontaine-maury/}
}

@book{tufteVisualDisplayQuantitative2001,
  title = {The {{Visual Display}} of {{Quantitative Information}}},
  author = {Tufte, Edward R.},
  year = {2001},
  publisher = {Graphics Press},
  abstract = {"This book deals with the theory and practice in the design of data graphics and makes the point that the most effective way to describe, explore, and summarize a set of numbers is to look at pictures of those numbers, through the use of statistical graphics, charts, and tables. It includes 250 illustrations of the best (and a few of the worst) statistical graphics, with detailed analysis of how to display data for precise, effective, quick analysis. Also offered is information on the design of the high-resolution displays, small multiples, editing and improving graphics, and the data-ink ratio. Time-series, relational graphics, data maps, multivariate designs, as well as detection of graphical deception: design variation vs. data variation, and sources of deception are discussed. Information on aesthetics and data graphical displays is included. The 2nd edition provides high-resolution color reproductions of the many graphics of William Playfair (1750-1800), adds color to other images where appropriate, and includes all the changes and corrections during the 17 printings of the 1st edition"--Publisher's description},
  googlebooks = {qmjNngEACAAJ},
  isbn = {978-1-930824-13-3},
  langid = {english},
  keywords = {Business & Economics / General,Science / General}
}

@misc{kaleyHistoricDataVisualizations2020,
  title = {Historic {{Data Visualizations}} --- {{Where}} Did It All Begin?},
  author = {Kaley, Aasavari},
  year = {2020},
  month = jul,
  journal = {Analytics Vidhya},
  urldate = {2024-08-03},
  abstract = {The only new thing in the world is the history you don't know{$\mkern1mu$}---{$\mkern1mu$}Harry S Truman},
  langid = {english}
}

@misc{szafirGoodBadBiased2018,
  title = {The Good, the Bad, and the Biased: {{Five}} Ways Visualizations Can Mislead (and How to Fix Them) {\textbar} {{ACM Interactions}}},
  author = {Szafir, Danielle},
  year = {2018},
  month = aug,
  journal = {Interactions},
  urldate = {2024-08-03},
  howpublished = {https://interactions.acm.org/archive/view/july-august-2018/the-good-the-bad-and-the-biased}
}

@misc{chengAnalyzingMinardVisualization2014,
  title = {Analyzing {{Minard}}'s {{Visualization Of Napoleon}}'s 1812 {{March}}},
  author = {Cheng, Joanne},
  year = {2014},
  month = jun,
  journal = {thoughtbot},
  urldate = {2024-08-03},
  abstract = {In The Visual Display of Quantitative Information, Edward Tufte calls...},
  howpublished = {https://thoughtbot.com/blog/analyzing-minards-visualization-of-napoleons-1812-march},
  langid = {english}
}

@article{mahbobiChapterFTestOneWay2015,
  title = {Chapter 6. {{F-Test}} and {{One-Way ANOVA}}},
  author = {Mahbobi, Mohammad and Tiemann, Thomas K.},
  year = {2015},
  month = dec,
  journal = {Introductory Business Statistics with Interactive Spreadsheets - 1st Canadian Edition},
  publisher = {BCcampus},
  urldate = {2024-08-10},
  langid = {english},
  file = {/Users/james/Zotero/storage/Q5DRT7MR/f-test-and-one-way-anova-2.html}
}

@misc{simplilearnDataScienceMinutes2018,
  title = {Data {{Science In}} 5 {{Minutes}} {\textbar} {{Data Science For Beginners}} {\textbar} {{What Is Data Science}}? {\textbar} {{Simplilearn}}},
  shorttitle = {Data {{Science In}} 5 {{Minutes}} {\textbar} {{Data Science For Beginners}} {\textbar} {{What Is Data Science}}?},
  author = {Simplilearn},
  year = {2018},
  month = dec,
  urldate = {2024-08-11},
  abstract = {🔥 Caltech Post Graduate Program In Data Science: https://www.simplilearn.com/post-graduate-program-data-science?utm\_campaign=DataScienceScribe\&utm\_medium=De...},
  langid = {british},
  file = {/Users/james/Zotero/storage/ZKEIRLWF/watch.html}
}

@misc{WhatDataScience2021,
  title = {What Is {{Data Science}}? {\textbar} {{IBM}}},
  shorttitle = {What Is {{Data Science}}?},
  year = {2021},
  month = sep,
  urldate = {2024-08-11},
  abstract = {Data science is a multidisciplinary approach to gaining insights from an increasing amount of data. IBM data science products help find the value of your data.},
  howpublished = {https://www.ibm.com/topics/data-science},
  langid = {american}
}

@article{buchananGettingStartedCreating2021,
  title = {Getting {{Started Creating Data Dictionaries}}: {{How}} to {{Create}} a {{Shareable Data Set}}},
  shorttitle = {Getting {{Started Creating Data Dictionaries}}},
  author = {Buchanan, Erin M. and Crain, Sarah E. and Cunningham, Ari L. and Johnson, Hannah R. and Stash, Hannah and {Papadatou-Pastou}, Marietta and Isager, Peder M. and Carlsson, Rickard and Aczel, Balazs},
  year = {2021},
  month = jan,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {4},
  number = {1},
  pages = {2515245920928007},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/2515245920928007},
  urldate = {2024-08-12},
  abstract = {As researchers embrace open and transparent data sharing, they will need to provide information about their data that effectively helps others understand their data sets' contents. Without proper documentation, data stored in online repositories such as OSF will often be rendered unfindable and unreadable by other researchers and indexing search engines. Data dictionaries and codebooks provide a wealth of information about variables, data collection, and other important facets of a data set. This information, called metadata, provides key insights into how the data might be further used in research and facilitates search-engine indexing to reach a broader audience of interested parties. This Tutorial first explains terminology and standards relevant to data dictionaries and codebooks. Accompanying information on OSF presents a guided workflow of the entire process from source data (e.g., survey answers on Qualtrics) to an openly shared data set accompanied by a data dictionary or codebook that follows an agreed-upon standard. Finally, we discuss freely available Web applications to assist this process of ensuring that psychology data are findable, accessible, interoperable, and reusable.},
  langid = {english},
  annotation = {14 citations (Semantic Scholar/DOI) [2024-08-13]},
  file = {/Users/james/Zotero/storage/7XY97CHG/Buchanan et al. - 2021 - Getting Started Creating Data Dictionaries How to.pdf}
}

@misc{amundsenAmundsen2024,
  title = {Amundsen},
  author = {Amundsen},
  year = {2024},
  journal = {Amundsen.io},
  urldate = {2024-08-12},
  howpublished = {https://www.amundsen.io/amundsen/},
  file = {/Users/james/Zotero/storage/JKGJCC6P/amundsen.html}
}

@article{meakerFacebookFinallyPuts2023,
  title = {Facebook {{Finally Puts}} a {{Price}} on {{Privacy}}: {{It}}'s \$10 a {{Month}}},
  shorttitle = {Facebook {{Finally Puts}} a {{Price}} on {{Privacy}}},
  author = {Meaker, Morgan},
  year = {2023},
  journal = {Wired},
  issn = {1059-1028},
  urldate = {2024-08-13},
  abstract = {Meta is about to roll out ad-free subscriptions on Instagram and Facebook. But critics say privacy should not be turned into a luxury.},
  chapter = {tags},
  langid = {american},
  keywords = {advertising,facebook,privacy,regulation},
  file = {/Users/james/Zotero/storage/Q6VCE7UA/meta-facebook-pay-for-privacy-europe.html}
}

@article{lichtensteinWhyOpenData2011,
  title = {Why {{Open Data Alone Is Not Enough}}},
  author = {Lichtenstein, Jesse},
  year = {2011},
  month = jun,
  journal = {Wired},
  volume = {19},
  number = {7},
  issn = {1059-1028},
  urldate = {2024-08-13},
  abstract = {Governments around the world are making data available. But ordinary people need to be told what's out there and how to use it.},
  chapter = {tags},
  langid = {american},
  file = {/Users/james/Zotero/storage/XQHFJC6M/st-essay-datafireworks.html}
}

@misc{soniKarnatakaOpenData2022,
  title = {Karnataka's Open Data Access: {{At}} What Cost?},
  shorttitle = {Karnataka's Open Data Access},
  author = {Soni, Shivam and {del\_ad\_min}},
  year = {2022},
  month = mar,
  journal = {The Data Economy Lab},
  urldate = {2024-08-13},
  abstract = {On October 19, the Government of Karnataka (GoK) notified its Open Data Policy (the ``Policy''). The Policy purports to achieve three overarching goals - one, eff},
  chapter = {Op-Eds},
  langid = {english},
  file = {/Users/james/Zotero/storage/2E4C6ZFU/karnatakas-open-data-access-at-what-cost.html}
}

@misc{hustenChocolateNobelPrizes,
  title = {Chocolate {{And Nobel Prizes Linked In Study}}},
  author = {Husten, Larry},
  journal = {Forbes},
  urldate = {2024-08-14},
  abstract = {Chocolate sampler (Peter Dazeley/Getty Images) You don't have to be a genius to like chocolate, but geniuses are more likely to eat lots of chocolate, at least according to a new paper published in the August New England Journal of Medicine.~Franz Messerli reports a highly significant correlation between a nation's per [...]},
  chapter = {Pharma \& Healthcare},
  howpublished = {https://www.forbes.com/sites/larryhusten/2012/10/10/chocolate-and-nobel-prizes-linked-in-study/},
  langid = {english},
  file = {/Users/james/Zotero/storage/PR474NPL/chocolate-and-nobel-prizes-linked-in-study.html}
}

@article{baruaEffectsMisinformationCOVID192020,
  title = {Effects of Misinformation on {{COVID-19}} Individual Responses and Recommendations for Resilience of Disastrous Consequences of Misinformation},
  author = {Barua, Zapan and Barua, Sajib and Aktar, Salma and Kabir, Najma and Li, Mingze},
  year = {2020},
  month = dec,
  journal = {Progress in Disaster Science},
  volume = {8},
  pages = {100119},
  issn = {2590-0617},
  doi = {10.1016/j.pdisas.2020.100119},
  urldate = {2024-08-14},
  abstract = {The proliferation of misinformation on social media platforms is faster than the spread of Corona Virus Diseases (COVID-19) and it can generate hefty deleterious consequences on health amid a disaster like COVID-19. Drawing upon research on the stimulus-response theory (hypodermic needle theory) and the resilience theory, this study tested a conceptual framework considering general misinformation belief, conspiracy belief, and religious misinformation belief as the stimulus; and credibility evaluations as resilience strategy; and their effects on COVID-19 individual responses. Using a self-administered online survey during the COVID-19 pandemic, the study obtained 483 useable responses and after test, finds that all-inclusive, the propagation of misinformation on social media undermines the COVID-19 individual responses. Particularly, credibility evaluation of misinformation strongly predicts the COVID-19 individual responses with positive influences and religious misinformation beliefs as well as conspiracy beliefs and general misinformation beliefs come next and influence negatively. The findings and general recommendations will help the public, in general, to be cautious about misinformation, and the respective authority of a country, in particular, for initiating proper safety measures about disastrous misinformation to protect the public health from being exploited.},
  keywords = {Coronavirus,COVID-19 individual response,Credibility evaluation,Misinformation,Social media},
  annotation = {259 citations (Semantic Scholar/DOI) [2024-08-14]},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/barua_et_al_2020_effects_of_misinformation_on_covid-19_individual_responses_and_recommendations.pdf;/Users/james/Zotero/storage/7YGMTMVL/S2590061720300569.html}
}

@incollection{friendlyMilestonesHistoryData2005,
  title = {Milestones in the {{History}} of {{Data Visualization}}: {{A Case Study}} in {{Statistical Historiography}}},
  shorttitle = {Milestones in the {{History}} of {{Data Visualization}}},
  booktitle = {Classification --- the {{Ubiquitous Challenge}}},
  author = {Friendly, Michael},
  editor = {Weihs, Claus and Gaul, Wolfgang},
  year = {2005},
  pages = {34--52},
  publisher = {Springer-Verlag},
  address = {Berlin/Heidelberg},
  doi = {10.1007/3-540-28084-7_4},
  urldate = {2024-08-14},
  isbn = {978-3-540-25677-9},
  langid = {english},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/friendly_2005_milestones_in_the_history_of_data_visualization.pdf}
}

@article{costigan-eavesEdwardTufteVisual1986,
  title = {Edward {{R}}. {{{\emph{Tufte The}}}}{\emph{ Visual Display of Quantitative Information}}},
  author = {{Costigan-Eaves}, Patricia},
  year = {1986},
  month = jan,
  journal = {Information Design Journal},
  volume = {4},
  number = {3},
  pages = {235--236},
  issn = {0142-5471, 1569-979X},
  doi = {10.1075/idj.4.3.12cos},
  urldate = {2024-08-14},
  langid = {english},
  annotation = {36 citations (Semantic Scholar/DOI) [2024-08-14]},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/costigan-eaves_1986_edward_r.pdf}
}

@article{rougierTenSimpleRules2014,
  title = {Ten {{Simple Rules}} for {{Better Figures}}},
  author = {Rougier, Nicolas P. and Droettboom, Michael and Bourne, Philip E.},
  year = {2014},
  month = sep,
  journal = {PLOS Computational Biology},
  volume = {10},
  number = {9},
  pages = {e1003833},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003833},
  urldate = {2024-08-14},
  langid = {english},
  keywords = {Computer software,Data visualization,Eye movements,Open source software,Radii,Renal cancer,Research design,Vision},
  annotation = {102 citations (Semantic Scholar/DOI) [2024-08-14]},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/rougier_et_al_2014_ten_simple_rules_for_better_figures.pdf}
}

@misc{mediaDataShapingFuture,
  title = {Data Is {{Shaping}} the {{Future}} of {{Journalism}}},
  author = {Media, O'Reilly},
  journal = {Forbes},
  urldate = {2024-08-15},
  abstract = {The MIT Civic Media conference and 2011 Knight News Challenge winners made it clear that data journalism and data tools will play key roles in the future of media and open government.},
  chapter = {Tech},
  howpublished = {https://www.forbes.com/sites/oreillymedia/2011/07/08/data-is-shaping-the-future-of-journalism/},
  langid = {english},
  file = {/Users/james/Zotero/storage/VLZSPJSH/data-is-shaping-the-future-of-journalism.html}
}

@misc{StorytellingDataCole,
  title = {Storytelling with {{Data}} {\textbar} {{Cole Nussbaumer Knaflic}} {\textbar} {{Talks}} at {{Google}}},
  urldate = {2024-08-17},
  abstract = {It's surprisingly easy to make a confusing graph. No one sets out with that purpose, but it happens frequently---across all industries and by all sorts of well...},
  langid = {british}
}

@article{lythreatisDigitalDivideReview2022,
  title = {The Digital Divide: {{A}} Review and Future Research Agenda},
  shorttitle = {The Digital Divide},
  author = {Lythreatis, Sophie and Singh, Sanjay Kumar and {El-Kassar}, Abdul-Nasser},
  year = {2022},
  month = feb,
  journal = {Technological Forecasting and Social Change},
  volume = {175},
  pages = {121359},
  issn = {0040-1625},
  doi = {10.1016/j.techfore.2021.121359},
  urldate = {2024-08-15},
  abstract = {This article provides a systematic review of the digital divide, a phenomenon which refers to disparities in Information and Communications Technology access, usage, and outcomes. It uniquely identifies the factors affecting the digital divide that have emerged in recent years (2017--2021) as well as investigate if there are new forms or levels of the divide that have surfaced in recent literature. The findings, based on 50 included studies, show that the factors affecting the digital divide can be classified into three different segments and nine main categories: sociodemographic, socioeconomic, personal elements, social support, type of technology, digital training, rights, infrastructure, and large-scale events. Out of all factors, education has been linked to the digital divide the most. The majority of recent literature have studied Level 2 of the divide. Also, only one article in the sample has considered the digital divide at the firm level. Findings also show that a new form, type-of-internet access, and two potential new levels of the digital divide, algorithmic awareness and data inequalities, have been identified in the contemporary literature. The results contribute to the understanding and development of the different perspectives of the digital divide concept. They also contribute to the stream of literature on the determinants of the divide and to the social inequalities and digital inclusion literature. This review can be seen as a guide for managers to realize and understand the forms that the divide can take and to delve into their organizational capabilities on the digitalization front and evaluate where further development is needed within their organizations to help diminish the divide.},
  keywords = {Determinants,Digital divide,Digital inequality,Levels,Systematic review},
  annotation = {202 citations (Semantic Scholar/DOI) [2024-08-17]},
  file = {/Users/james/Zotero/storage/6AE7PPC6/S0040162521007903.html}
}

@misc{DigitalSkillsInclusion,
  title = {2. {{Digital}} Skills and Inclusion - Giving Everyone Access to the Digital Skills They Need},
  journal = {GOV.UK},
  urldate = {2024-08-15},
  howpublished = {https://www.gov.uk/government/publications/uk-digital-strategy/2-digital-skills-and-inclusion-giving-everyone-access-to-the-digital-skills-they-need},
  langid = {english},
  file = {/Users/james/Zotero/storage/8NZTHQA7/2-digital-skills-and-inclusion-giving-everyone-access-to-the-digital-skills-they-need.html}
}

@misc{UKHSADataDashboard,
  title = {{{UKHSA}} Data Dashboard},
  urldate = {2024-08-17},
  abstract = {Overall summary of the respiratory viruses in circulation within the UK},
  howpublished = {https://ukhsa-dashboard.data.gov.uk},
  langid = {english},
  file = {/Users/james/Zotero/storage/JNICJ5NF/ukhsa-dashboard.data.gov.uk.html}
}

@misc{SpuriousCorrelations,
  title = {Spurious {{Correlations}}},
  urldate = {2024-08-17},
  abstract = {Correlation is not causation: thousands of charts of real data showing actual correlations between ridiculous variables.},
  howpublished = {https://www.tylervigen.com/spurious-correlations},
  langid = {english},
  file = {/Users/james/Zotero/storage/DGH4RG8C/spurious-correlations.html}
}

@misc{hustenChocolateNobelPrizesa,
  title = {Chocolate {{And Nobel Prizes Linked In Study}}},
  author = {Husten, Larry},
  journal = {Forbes},
  urldate = {2024-08-17},
  abstract = {Chocolate sampler (Peter Dazeley/Getty Images) You don't have to be a genius to like chocolate, but geniuses are more likely to eat lots of chocolate, at least according to a new paper published in the August New England Journal of Medicine.~Franz Messerli reports a highly significant correlation between a nation's per [...]},
  chapter = {Pharma \& Healthcare},
  howpublished = {https://www.forbes.com/sites/larryhusten/2012/10/10/chocolate-and-nobel-prizes-linked-in-study/},
  langid = {english},
  file = {/Users/james/Zotero/storage/GAZQ9K74/chocolate-and-nobel-prizes-linked-in-study.html}
}

@article{messerliChocolateConsumptionCognitive2012,
  title = {Chocolate {{Consumption}}, {{Cognitive Function}}, and {{Nobel Laureates}}},
  author = {Messerli, Franz H.},
  year = {2012},
  month = oct,
  journal = {New England Journal of Medicine},
  volume = {367},
  number = {16},
  pages = {1562--1564},
  publisher = {Massachusetts Medical Society},
  issn = {0028-4793},
  doi = {10.1056/NEJMon1211064},
  urldate = {2024-08-17},
  abstract = {Chocolate consumption could hypothetically improve cognitive function not only in individuals but in whole populations. Could there be a correlation between a country's level of chocolate consumption and its total number of Nobel laureates per capita? Dietary flavonoids, abundant in plant-based foods, have been shown to improve cognitive function. Specifically, a reduction in the risk of dementia, enhanced performance on some cognitive tests, and improved cognitive function in elderly patients with mild impairment have been associated with a regular intake of flavonoids.1,2 A subclass of flavonoids called flavanols, which are widely present in cocoa, green tea, red wine, and some fruits, seems to be effective in slowing down or even reversing the reductions in cognitive performance that occur with aging. Dietary flavanols have also been shown to improve endothelial function and to lower blood pressure .~.~.},
  annotation = {172 citations (Semantic Scholar/DOI) [2024-08-17]}
}

@article{rougierTenSimpleRules2014a,
  title = {Ten {{Simple Rules}} for {{Better Figures}}},
  author = {Rougier, Nicolas P. and Droettboom, Michael and Bourne, Philip E.},
  year = {2014},
  month = sep,
  journal = {PLOS Computational Biology},
  volume = {10},
  number = {9},
  pages = {e1003833},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003833},
  urldate = {2024-08-17},
  langid = {english},
  keywords = {Computer software,Data visualization,Eye movements,Open source software,Radii,Renal cancer,Research design,Vision},
  annotation = {102 citations (Semantic Scholar/DOI) [2024-08-17]},
  file = {/Users/james/Library/CloudStorage/GoogleDrive-drohnwerks@gmail.com/My Drive/Zotero/rougier_et_al_2014_ten_simple_rules_for_better_figures2.pdf}
}

@misc{DataLiteracyExplained,
  title = {Data Literacy Explained: {{Definition}}, Examples \& More {\textbar} {{Tableau}}},
  shorttitle = {Data Literacy Explained},
  urldate = {2024-08-20},
  abstract = {Data literacy is increasingly important in the professional world. Learn all about what it is and what it means for you.},
  howpublished = {https://www.tableau.com/data-insights/data-literacy/what-is},
  langid = {american},
  file = {/Users/james/Zotero/storage/GGD5C25A/what-is.html}
}

@book{tetlockSuperforecastingArtScience2015,
  title = {Superforecasting : {{The Art}} and {{Science}} of {{Predicti}}},
  shorttitle = {Superforecasting},
  author = {Tetlock, Philip E. and Gardner, Dan},
  year = {2015},
  publisher = {Crown Publishers},
  abstract = {From one of the world's most highly regarded social scientists comes a seminal book on forecasting that shows, for the first time, how we can all get better at making predictions.~~~~~~ In Superforecasting, Tetlock and coauthor Dan Gardner offer a masterwork on prediction, drawing on decades of research and the results of a massive, government-funded forecasting tournament. The Good Judgment Project involves tens of thousands of ordinary people--including a Brooklyn filmmaker, a retired pipe installer, and a former ballroom dancer--who set out to forecast global events. Some of the volunteers have turned out to be astonishingly good. They've beaten other benchmarks, competitors, and prediction markets. They've even beaten the collective judgment of intelligence analysts with access to classified information. They are "superforecasters." ~~~~ The authors show us how we can learn from this elite group. Weaving together stories of forecasting successes (the raid on Osama bin Laden's compound) and failures (the Bay of Pigs) and interviews with a range of high-level decision makers, from David Petraeus to Robert Rubin, they show that good forecasting doesn't require powerful computers or arcane methods. It involves gathering evidence from a variety of sources, learning to think probabilistically, working in teams, keeping score, and being willing to admit error and change course. ~~~~ Superforecasting offers the first demonstrably effective way to improve our ability to predict the future--whether in business, finance, politics, international affairs, or daily life--and is destined to become a modern classic.},
  isbn = {978-0-7710-7052-5},
  langid = {english}
}
